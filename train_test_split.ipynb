{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8956138c",
   "metadata": {},
   "source": [
    "# Split data and prepare windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292dcc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocess.ipynb\n",
    "%run sys_configs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "980b09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c62b8f",
   "metadata": {},
   "source": [
    "This notebook contains functions to split the MyoGym dataset into train, validation and test sets and compute windows from each time series data stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58afed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(data) # Length of data stream and dimensionality\n",
    "step = 50 # Step size forward through the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b61f4628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ordered list of columns is ['acc_x', 'acc_y', 'acc_z', 'gyr_x', 'gyr_y', 'gyr_z', 'activity', 'trainer', 'time']\n"
     ]
    }
   ],
   "source": [
    "columns = list(data.columns)\n",
    "print(\"The ordered list of columns is {}\".format(columns))\n",
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b189cc",
   "metadata": {},
   "source": [
    "In most contexts involving time series, the validation dataset is temporally separated from the train dataset. In both window methods, we consider windows to be independent, i.e. we can ignore any information from temporally preceding windows.\n",
    "\n",
    "There are two windowing methods we will deploy for GAR tasks. We will then normalise the data.\n",
    "\n",
    "Data normalisation is essential to the process of adjusting all channels to an identical range. Many time series classification techniques that we will consider as benchmarks, for example Dynamic Time Warping, use distance metrics that depend on each dimension having the same scale. We use sklearn's StandardScalar.\n",
    "\n",
    "The use of a standard scaling allows us to more easily identify outliers and to more rigorously quantify the extent of these outliers using hypothesis tests of a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c001275",
   "metadata": {},
   "source": [
    "### Window Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e420f4d",
   "metadata": {},
   "source": [
    "This incorporates only a fixed number of the observations, if there is no activity or trainer changes in the window.\n",
    "\n",
    "This is a less sophisticated windowing strategy intended for benchmarking methods which rely on fixed length time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9977520",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 500 # Window length is 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "068a1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer1 = np.arange(T)[None, :] + np.arange(start = 0, stop = N-T, step = step)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "790365c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of windows_1 (32170, 500, 9)\n"
     ]
    }
   ],
   "source": [
    "windows1 = data[indexer1]\n",
    "print(\"The shape of windows_1 {}\".format(windows1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "535280da",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_counts1 = np.apply_along_axis(lambda x: len(np.unique(x)), axis=1, arr=windows1[:, :, 6])\n",
    "trainer_counts1 = np.apply_along_axis(lambda x: len(np.unique(x)), axis=1, arr=windows1[:, :, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf01db8",
   "metadata": {},
   "source": [
    "Exclude all windows in which either the activity or the trainer changes. Each window should be *pure*, i.e. it should be mappable to exactly one trainer and one activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea4e831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = windows1[(activity_counts1 == 1) & (trainer_counts1 == 1), :, :6] # Acceleration & Gyroscope data\n",
    "y1 = windows1[(activity_counts1 == 1) & (trainer_counts1 == 1), 0, 6] # Activities. Take the first element of the time series (though every element is the same)\n",
    "t1 = windows1[(activity_counts1 == 1) & (trainer_counts1 == 1), 0, 7] # Trainers. Take the first element of the time series (though every element is the same)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c3c6a",
   "metadata": {},
   "source": [
    "**Split into train/validation/test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be56463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers1 = np.unique(t1)\n",
    "shuffled_trainers1 = np.random.permutation(trainers1)\n",
    "\n",
    "# Split the indexes into a combined (train, val) index set and the test indexes\n",
    "comb_idxs1 = np.where(np.isin(t1, shuffled_trainers1[:8]))[0]\n",
    "test_idxs1 = np.where(np.isin(t1, shuffled_trainers1[8:]))[0]\n",
    "\n",
    "# Split out the combined (train, val) index set\n",
    "n1 = len(comb_idxs1)\n",
    "train_idxs1 = comb_idxs1[:int(0.8*n1)]\n",
    "val_idxs1 = comb_idxs1[int(0.8*n1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e75c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs1 = np.random.permutation(train_idxs1)\n",
    "val_idxs1 = np.random.permutation(val_idxs1)\n",
    "test_idxs1 = np.random.permutation(test_idxs1)\n",
    "\n",
    "x1_train = x1[train_idxs1]\n",
    "x1_val = x1[val_idxs1]\n",
    "x1_test = x1[test_idxs1]\n",
    "\n",
    "y1_train = y1[train_idxs1]\n",
    "y1_val = y1[val_idxs1]\n",
    "y1_test = y1[test_idxs1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784004a0",
   "metadata": {},
   "source": [
    "#### Data normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69895edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = StandardScaler()\n",
    "\n",
    "N1_train, T1 , D1 = x1_train.shape\n",
    "N1_val, _ , _ = x1_val.shape\n",
    "N1_test, _ , _ = x1_test.shape\n",
    "\n",
    "# Standard scaler works only for 2 dimensional data, so we melt the time dimension into the sample dimension\n",
    "x1_train = x1_train.reshape(N1_train * T1, D1)\n",
    "x1_val = x1_val.reshape(N1_val * T1, D1)\n",
    "x1_test = x1_test.reshape(N1_test * T1, D1)\n",
    "\n",
    "# Fit the standard scaler to the train data, then transform the validation and test data\n",
    "x1_train = scaler1.fit_transform(x1_train)\n",
    "x1_val = scaler1.transform(x1_val)\n",
    "x1_test = scaler1.transform(x1_test)\n",
    "\n",
    "# Transform back to the N X T X D shape\n",
    "x1_train = x1_train.reshape(N1_train, T1, D1)\n",
    "x1_val = x1_val.reshape(N1_val, T1, D1)\n",
    "x1_test = x1_test.reshape(N1_test, T1, D1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf6fc0a",
   "metadata": {},
   "source": [
    "### Window Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67232e23",
   "metadata": {},
   "source": [
    "**Window technique 2**: incorporates variable length time series windows up to a maximum length denoted as `T2` by placing a mask over the time steps. The mask is constrained so the unmasked time steps are consecutive. The mask can be experimented with in order to explore how its length implacts the predictive ability of the models tested. Many of the steps in this method remain the same as window method 1, but for the additional masking step.\n",
    "\n",
    "The motivation behind this approach is that in the real world, there is a short period at the beginning of the data collection where the only time steps available with which to make a classification are those up to the current time step, which is less than time step `T2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cb9482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T2 = 1000 # Maximum window length is 1,000. In general, windows will be shorter than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76c4d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer2 = np.arange(T2)[None, :] + np.arange(start = 0, stop = N-T2, step = step)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5b8c52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of windows_2 (32160, 1000, 9)\n"
     ]
    }
   ],
   "source": [
    "windows2 = data[indexer2]\n",
    "print(\"The shape of windows_2 {}\".format(windows2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99865a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_counts2 = np.apply_along_axis(lambda x: len(np.unique(x)), axis=1, arr=windows2[:, :, 6])\n",
    "trainer_counts2 = np.apply_along_axis(lambda x: len(np.unique(x)), axis=1, arr=windows2[:, :, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f833229",
   "metadata": {},
   "source": [
    "Each window should be *pure*, i.e. it should be designated exactly 1 trainer and 1 activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d07b34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For windows in which either the activity or the trainer changes. Each window should be \"pure\", i.e. it should be designated exactly 1 trainer and 1 activity\n",
    "x2 = windows2[(activity_counts2 == 1) & (trainer_counts2 == 1), :, :6] # Acceleration & Gyroscope data\n",
    "y2 = windows2[(activity_counts2 == 1) & (trainer_counts2 == 1), 0, 6] # Activities. Take the first element of the time series (though every element is the same)\n",
    "t2 = windows2[(activity_counts2 == 1) & (trainer_counts2 == 1), 0, 7] # Trainers. Take the first element of the time series (though every element is the same)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4095de35",
   "metadata": {},
   "source": [
    "We now apply a mask whose beginning and ending indexes are specific to each sample; this is because we are testing a range of different mask lengths. Both positions are randomly assigned; the starting position must be $\\leq$ `start_index` and the ending position must be $\\geq$ `end_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8695622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and end indexes of where the mask values are True, for each row\n",
    "start_indexes = np.random.randint(low = 0, high = 400, size=len(x2))\n",
    "end_indexes = np.random.randint(low = 800, high = T2 - 1, size=len(x2))\n",
    "\n",
    "# Define the mask matrix with all values set to True with the first two dimensions as the data matrix.\n",
    "m2 = np.full_like(x2, True)[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4f291e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable to generate the rows of the mask matrix\n",
    "cols = np.arange(T2)[None, :]\n",
    "\n",
    "# Use broadcasting to set to False all elements which are not in the mask\n",
    "update_mask_lt = cols < start_indexes[:, None]\n",
    "update_mask_gt = cols > end_indexes[:, None]\n",
    "\n",
    "m2[update_mask_lt] = False\n",
    "m2[update_mask_gt] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5000054a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of false values in the mask is 6070709\n",
      "The number of false values implied by the variables start_indexes and end_indexes is 6070709\n"
     ]
    }
   ],
   "source": [
    "# Briefly check the mask has been correctly updated by counting up the number of its elements that are set to False vs the number implied to be False from the update masks\n",
    "mask_total_false = np.sum(m2 == False)\n",
    "\n",
    "start_indexes_total_false = np.sum(start_indexes)\n",
    "end_indexes_total_false = np.sum(T2 - 1 - end_indexes)\n",
    "\n",
    "print(\"The number of false values in the mask is {}\\nThe number of false values implied by the variables start_indexes and end_indexes is {}\".format(mask_total_false, start_indexes_total_false + end_indexes_total_false))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ed3f0",
   "metadata": {},
   "source": [
    "**Split into train/validation/test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a0ac21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers2 = np.unique(t2)\n",
    "shuffled_trainers2 = np.random.permutation(trainers2)\n",
    "\n",
    "# Split the indexes into a combined (train, val) index set and the test indexes\n",
    "comb_idxs2 = np.where(np.isin(t2, shuffled_trainers2[:8]))[0]\n",
    "test_idxs2 = np.where(np.isin(t2, shuffled_trainers2[8:]))[0]\n",
    "\n",
    "# Split out the combined (train, val) index set\n",
    "n2 = len(comb_idxs2)\n",
    "train_idxs2 = comb_idxs2[:int(0.8*n2)]\n",
    "val_idxs2 = comb_idxs2[int(0.8*n2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41666e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs2 = np.random.permutation(train_idxs2)\n",
    "val_idxs2 = np.random.permutation(val_idxs2)\n",
    "test_idxs2 = np.random.permutation(test_idxs2)\n",
    "\n",
    "x2_train = x2[train_idxs2, :]\n",
    "x2_val = x2[val_idxs2, :]\n",
    "x2_test = x2[test_idxs2, :]\n",
    "\n",
    "y2_train = y2[train_idxs2]\n",
    "y2_val = y2[val_idxs2]\n",
    "y2_test = y2[test_idxs2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b22d83",
   "metadata": {},
   "source": [
    "#### Data normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa9482d",
   "metadata": {},
   "source": [
    "We do not normalise the outputs of the second windowing method. This method is only used for neural networks, and the scale should be absorbed in the weights of the activation functions.\n",
    "\n",
    "The masking also complicates the normalisation calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f5828",
   "metadata": {},
   "source": [
    "## Sample background activity class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92889014",
   "metadata": {},
   "source": [
    "According to the paper [1] which introduced the MyoGym dataset, the background activity class, which it describes as the null class, accounts for 77% of the dataset, a number which dwarves the remaining 30 classes. Most of the techniques we explore are sensitive to class imbalanaces or to dataset sizes. Therefore, drawing on conclusions from the exploratory data analysis in the appendix, we sample some windows from this background activity class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2687d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_background_activity_class(data: np.array, labels: np.array, sz: int):\n",
    "    \"\"\"\n",
    "    Removes most samples from the dominant background activity class, down to a sample size (sz) specified in this function.  \n",
    "    \"\"\"\n",
    "    # Identify indices of the noise class and signal class\n",
    "    noise_idx = np.where(labels == 0)[0]\n",
    "    signal_idx = np.where(labels != 0)[0]\n",
    "\n",
    "    # Choose a sample from the noise class\n",
    "    sample_idx = np.random.choice(noise_idx, size = sz, replace=False)\n",
    "\n",
    "    # Combine the sampled indices with the other class indices\n",
    "    combined_idx = np.concatenate([signal_idx, sample_idx])\n",
    "    combined_idx = np.random.permutation(combined_idx)\n",
    "\n",
    "    # Apply the indexes to the data and labels\n",
    "    data_sample = data[combined_idx, :, :]\n",
    "    labels_sample = labels[combined_idx]\n",
    "    \n",
    "    return data_sample, labels_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f720c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1s_train, y1s_train = sample_background_activity_class(data = x1_train, labels = y1_train, sz = 150)\n",
    "x1s_val, y1s_val = sample_background_activity_class(data = x1_val, labels = y1_val, sz = 40)\n",
    "x1s_test, y1s_test = sample_background_activity_class(data = x1_test, labels = y1_test, sz = 50)\n",
    "\n",
    "x2s_train, y2s_train = sample_background_activity_class(data = x2_train, labels = y2_train, sz = 150)\n",
    "x2s_val, y2s_val = sample_background_activity_class(data = x2_val, labels = y2_val, sz = 40)\n",
    "x2s_test, y2s_test = sample_background_activity_class(data = x2_test, labels = y2_test, sz = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed7e8e4",
   "metadata": {},
   "source": [
    "## Save datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239d5b36",
   "metadata": {},
   "source": [
    "We save the sampled datasets to train, validation and test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9da4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/1s_train.npy', 'wb') as f:\n",
    "    np.save(f, x1s_train)\n",
    "    np.save(f, y1s_train)\n",
    "    \n",
    "with open('data/1s_val.npy', 'wb') as f:\n",
    "    np.save(f, x1s_val)\n",
    "    np.save(f, y1s_val)\n",
    "    \n",
    "with open('data/1s_test.npy', 'wb') as f:\n",
    "    np.save(f, x1s_test)\n",
    "    np.save(f, y1s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5021f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/2s_train.npy', 'wb') as f:\n",
    "    np.save(f, x2s_train)\n",
    "    np.save(f, y2s_train)\n",
    "    \n",
    "with open('data/2s_val.npy', 'wb') as f:\n",
    "    np.save(f, x2s_val)\n",
    "    np.save(f, y2s_val)\n",
    "    \n",
    "with open('data/2s_test.npy', 'wb') as f:\n",
    "    np.save(f, x2s_test)\n",
    "    np.save(f, y2s_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac88cd0",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c717f",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d82eaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_counts(y_train, y_val, y_test):\n",
    "    train_labels, train_counts = np.unique(y_train, return_counts = True)\n",
    "    val_labels, val_counts = np.unique(y_val, return_counts = True)\n",
    "    test_labels, test_counts = np.unique(y_test, return_counts = True)\n",
    "\n",
    "    train_label_counts = pd.DataFrame(np.hstack([train_labels[:, np.newaxis], train_counts[:, np.newaxis]]), columns = [\"Label\", \"Train Count\"])\n",
    "    val_label_counts = pd.DataFrame(np.hstack([val_labels[:, np.newaxis], val_counts[:, np.newaxis]]), columns = [\"Label\", \"Val Count\"])\n",
    "    test_label_counts = pd.DataFrame(np.hstack([test_labels[:, np.newaxis], test_counts[:, np.newaxis]]), columns = [\"Label\", \"Test Count\"])\n",
    "    \n",
    "    label_counts = train_label_counts.merge(test_label_counts, how = \"outer\", on = \"Label\").merge(val_label_counts, how = \"outer\", on = \"Label\")\n",
    "    label_counts[\"Label\"] = label_counts[\"Label\"].map(ACTIVITY_MAPPING)\n",
    "    label_counts = label_counts.set_index(\"Label\")\n",
    "    label_counts = label_counts.sort_values([\"Train Count\"], ascending=[False])\n",
    "    \n",
    "    return label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db978710",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts_1 = get_activity_counts(y1_train, y1_val, y1_test)\n",
    "label_counts_2 = get_activity_counts(y2_train, y2_val, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ec885e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts_1.columns = pd.MultiIndex.from_product([['Window Method 1'], label_counts_1.columns])\n",
    "label_counts_2.columns = pd.MultiIndex.from_product([['Window Method 2'], label_counts_2.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f93e7166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Window Method 1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Window Method 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Train Count</th>\n",
       "      <th>Test Count</th>\n",
       "      <th>Val Count</th>\n",
       "      <th>Train Count</th>\n",
       "      <th>Test Count</th>\n",
       "      <th>Val Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bar Skullcrusher</th>\n",
       "      <td>105.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bench Dip / Dip</th>\n",
       "      <td>62.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bench Press</th>\n",
       "      <td>68.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bent Over Barbell Row</th>\n",
       "      <td>59.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cable Curl</th>\n",
       "      <td>89.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car Drivers</th>\n",
       "      <td>63.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close-Grip Barbell Bench Press</th>\n",
       "      <td>89.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concentration Curl</th>\n",
       "      <td>90.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dumbbell Alternate Bicep Curl</th>\n",
       "      <td>167.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dumbbell Flyes</th>\n",
       "      <td>160.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Front Dumbbell Raise</th>\n",
       "      <td>167.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hammer Curl</th>\n",
       "      <td>127.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incline Dumbbell Flyes</th>\n",
       "      <td>143.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incline Dumbbell Press</th>\n",
       "      <td>123.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incline Hammer Curl</th>\n",
       "      <td>105.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leverage Chest Press</th>\n",
       "      <td>90.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lying Rear Delt Raise</th>\n",
       "      <td>69.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No activity identified</th>\n",
       "      <td>14665.0</td>\n",
       "      <td>3573.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>13003.0</td>\n",
       "      <td>2442.0</td>\n",
       "      <td>3193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Arm Dumbbell Row</th>\n",
       "      <td>81.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overhead Triceps Extension</th>\n",
       "      <td>78.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pushups</th>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reverse Grip Bent-Over Row</th>\n",
       "      <td>57.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seated Cable Rows</th>\n",
       "      <td>101.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seated Dumbbell Shoulder Press</th>\n",
       "      <td>89.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Side Lateral Raise</th>\n",
       "      <td>85.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spider Curl</th>\n",
       "      <td>120.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tricep Dumbbell Kickback</th>\n",
       "      <td>58.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Triceps Pushdown</th>\n",
       "      <td>79.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upright Barbell Row</th>\n",
       "      <td>85.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wide-Grip Front Pulldown</th>\n",
       "      <td>109.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wide-Grip Pulldown Behind The Neck</th>\n",
       "      <td>112.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Window Method 1                       \\\n",
       "                                       Train Count Test Count Val Count   \n",
       "Label                                                                     \n",
       "Bar Skullcrusher                             105.0       31.0      35.0   \n",
       "Bench Dip / Dip                               62.0       20.0      27.0   \n",
       "Bench Press                                   68.0       17.0      23.0   \n",
       "Bent Over Barbell Row                         59.0       12.0      14.0   \n",
       "Cable Curl                                    89.0       17.0      25.0   \n",
       "Car Drivers                                   63.0       28.0       9.0   \n",
       "Close-Grip Barbell Bench Press                89.0        9.0      26.0   \n",
       "Concentration Curl                            90.0       13.0      32.0   \n",
       "Dumbbell Alternate Bicep Curl                167.0       32.0      77.0   \n",
       "Dumbbell Flyes                               160.0       15.0      47.0   \n",
       "Front Dumbbell Raise                         167.0       28.0      55.0   \n",
       "Hammer Curl                                  127.0       35.0      59.0   \n",
       "Incline Dumbbell Flyes                       143.0       23.0      48.0   \n",
       "Incline Dumbbell Press                       123.0       19.0      32.0   \n",
       "Incline Hammer Curl                          105.0       24.0      38.0   \n",
       "Leverage Chest Press                          90.0       19.0      24.0   \n",
       "Lying Rear Delt Raise                         69.0       22.0      24.0   \n",
       "No activity identified                     14665.0     3573.0    3436.0   \n",
       "One-Arm Dumbbell Row                          81.0       17.0      25.0   \n",
       "Overhead Triceps Extension                    78.0       20.0      35.0   \n",
       "Pushups                                       53.0        5.0      20.0   \n",
       "Reverse Grip Bent-Over Row                    57.0       12.0      10.0   \n",
       "Seated Cable Rows                            101.0       19.0      34.0   \n",
       "Seated Dumbbell Shoulder Press                89.0       13.0      29.0   \n",
       "Side Lateral Raise                            85.0       22.0      27.0   \n",
       "Spider Curl                                  120.0       25.0      31.0   \n",
       "Tricep Dumbbell Kickback                      58.0       18.0      36.0   \n",
       "Triceps Pushdown                              79.0       14.0      32.0   \n",
       "Upright Barbell Row                           85.0       13.0      25.0   \n",
       "Wide-Grip Front Pulldown                     109.0       10.0      27.0   \n",
       "Wide-Grip Pulldown Behind The Neck           112.0       24.0      26.0   \n",
       "\n",
       "                                   Window Method 2                       \n",
       "                                       Train Count Test Count Val Count  \n",
       "Label                                                                    \n",
       "Bar Skullcrusher                              48.0        5.0      20.0  \n",
       "Bench Dip / Dip                                8.0        4.0       4.0  \n",
       "Bench Press                                   18.0        4.0       7.0  \n",
       "Bent Over Barbell Row                          5.0        3.0       2.0  \n",
       "Cable Curl                                    28.0        3.0       8.0  \n",
       "Car Drivers                                    3.0        2.0       9.0  \n",
       "Close-Grip Barbell Bench Press                20.0       13.0      13.0  \n",
       "Concentration Curl                            26.0        5.0      13.0  \n",
       "Dumbbell Alternate Bicep Curl                102.0       35.0      39.0  \n",
       "Dumbbell Flyes                                85.0       28.0      14.0  \n",
       "Front Dumbbell Raise                          95.0       35.0      20.0  \n",
       "Hammer Curl                                   58.0       35.0      28.0  \n",
       "Incline Dumbbell Flyes                        73.0       24.0      17.0  \n",
       "Incline Dumbbell Press                        55.0       13.0       7.0  \n",
       "Incline Hammer Curl                           40.0       12.0      15.0  \n",
       "Leverage Chest Press                          26.0        3.0      12.0  \n",
       "Lying Rear Delt Raise                         18.0        5.0       4.0  \n",
       "No activity identified                     13003.0     2442.0    3193.0  \n",
       "One-Arm Dumbbell Row                          18.0        7.0       6.0  \n",
       "Overhead Triceps Extension                    26.0        2.0       8.0  \n",
       "Pushups                                        3.0        2.0       7.0  \n",
       "Reverse Grip Bent-Over Row                     6.0        2.0       NaN  \n",
       "Seated Cable Rows                             37.0        7.0      12.0  \n",
       "Seated Dumbbell Shoulder Press                28.0        4.0       8.0  \n",
       "Side Lateral Raise                            25.0        5.0       6.0  \n",
       "Spider Curl                                   63.0        8.0       9.0  \n",
       "Tricep Dumbbell Kickback                      15.0        NaN       8.0  \n",
       "Triceps Pushdown                              23.0        4.0       8.0  \n",
       "Upright Barbell Row                           29.0        1.0       6.0  \n",
       "Wide-Grip Front Pulldown                      43.0        6.0       9.0  \n",
       "Wide-Grip Pulldown Behind The Neck            52.0        5.0       8.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts_1.merge(label_counts_2, how = \"outer\", left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc6de9",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b96a7c",
   "metadata": {},
   "source": [
    "[1] Koskimäki, Heli, Pekka Siirtola and Juha Röning. “MyoGym: introducing an open gym data set for activity recognition collected using myo armband.” Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers (2017): n. pag."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
