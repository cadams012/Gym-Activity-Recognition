{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8956138c",
   "metadata": {},
   "source": [
    "# Split data and prepare windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292dcc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocess.ipynb\n",
    "%run sys_configs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "980b09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c62b8f",
   "metadata": {},
   "source": [
    "This notebook contains functions to split the MyoGym dataset into train, validation and test sets and compute windows from each time series data stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58afed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(data) # Length of data stream and dimensionality\n",
    "step = 50 # Step size forward through the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b61f4628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ordered list of columns is ['acc_x', 'acc_y', 'acc_z', 'gyr_x', 'gyr_y', 'gyr_z', 'activity', 'trainer', 'time']\n"
     ]
    }
   ],
   "source": [
    "columns = list(data.columns)\n",
    "print(\"The ordered list of columns is {}\".format(columns))\n",
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b189cc",
   "metadata": {},
   "source": [
    "In most contexts involving time series, the validation dataset is temporally separated from the train dataset. In both window methods, we consider windows to be independent, i.e. we can ignore any information from temporally preceding windows.\n",
    "\n",
    "There are two windowing methods we will deploy for GAR tasks. We will then normalise the data.\n",
    "\n",
    "Data normalisation is essential to the process of adjusting all channels to an identical range. Many time series classification techniques that we will consider as benchmarks, for example Dynamic Time Warping, use distance metrics that depend on each dimension having the same scale. We use sklearn's StandardScalar.\n",
    "\n",
    "The use of a standard scaling allows us to more easily identify outliers and to more rigorously quantify the extent of these outliers using hypothesis tests of a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c001275",
   "metadata": {},
   "source": [
    "### Applying Sliding Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e420f4d",
   "metadata": {},
   "source": [
    "This incorporates only a fixed number of the observations, if there is no activity or trainer changes in the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9977520",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 500 # Window length is 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "068a1fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = np.arange(T)[None, :] + np.arange(start = 0, stop = N-T, step = step)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "790365c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of windows (32170, 500, 9)\n"
     ]
    }
   ],
   "source": [
    "windows = data[indexer]\n",
    "print(\"The shape of windows {}\".format(windows.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "535280da",
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_counts = np.apply_along_axis(lambda x: len(np.unique(x)), axis=1, arr=windows[:, :, 6])\n",
    "trainer_counts = np.apply_along_axis(lambda x: len(np.unique(x)), axis=1, arr=windows[:, :, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf01db8",
   "metadata": {},
   "source": [
    "Exclude all windows in which either the activity or the trainer changes. Each window should be *pure*, i.e. it should be mappable to exactly one trainer and one activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea4e831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = windows[(activity_counts == 1) & (trainer_counts == 1), :, :6] # Acceleration & Gyroscope data\n",
    "y = windows[(activity_counts == 1) & (trainer_counts == 1), 0, 6] # Activities. Take the first element of the time series (though every element is the same)\n",
    "t = windows[(activity_counts == 1) & (trainer_counts == 1), 0, 7] # Trainers. Take the first element of the time series (though every element is the same)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6c3c6a",
   "metadata": {},
   "source": [
    "**Split into train/validation/test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be56463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainers = np.unique(t)\n",
    "shuffled_trainers = np.random.permutation(trainers)\n",
    "\n",
    "# Split the indexes into a combined (train, val) index set and the test indexes\n",
    "comb_idxs = np.where(np.isin(t, shuffled_trainers[:8]))[0]\n",
    "test_idxs = np.where(np.isin(t, shuffled_trainers[8:]))[0]\n",
    "\n",
    "# Split out the combined (train, val) index set\n",
    "n = len(comb_idxs)\n",
    "train_idxs = comb_idxs[:int(0.8*n)]\n",
    "val_idxs = comb_idxs[int(0.8*n):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e75c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = np.random.permutation(train_idxs)\n",
    "val_idxs = np.random.permutation(val_idxs)\n",
    "test_idxs = np.random.permutation(test_idxs)\n",
    "\n",
    "x_train = x[train_idxs]\n",
    "x_val = x[val_idxs]\n",
    "x_test = x[test_idxs]\n",
    "\n",
    "y_train = y[train_idxs]\n",
    "y_val = y[val_idxs]\n",
    "y_test = y[test_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784004a0",
   "metadata": {},
   "source": [
    "#### Data normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69895edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "N_train, T , D = x_train.shape\n",
    "N_val, _ , _ = x_val.shape\n",
    "N_test, _ , _ = x_test.shape\n",
    "\n",
    "# MinMaxScaler scaler works only for 2 dimensional data, so we melt the time dimension into the sample dimension\n",
    "x_train = x_train.reshape(N_train * T, D)\n",
    "x_val = x_val.reshape(N_val * T, D)\n",
    "x_test = x_test.reshape(N_test * T, D)\n",
    "\n",
    "# Fit the scaler to the train data, then transform the validation and test data\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Transform back to the N X T X D shape\n",
    "x_train = x_train.reshape(N_train, T, D)\n",
    "x_val = x_val.reshape(N_val, T, D)\n",
    "x_test = x_test.reshape(N_test, T, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f5828",
   "metadata": {},
   "source": [
    "## Sample background activity class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92889014",
   "metadata": {},
   "source": [
    "According to the paper [1] which introduced the MyoGym dataset, the background activity class, which it describes as the null class, accounts for 77% of the dataset, a number which dwarves the remaining 30 classes. Many TSC techniques are sensitive to class imbalanaces or to dataset sizes. Therefore, drawing on conclusions from the exploratory data analysis in the appendix, we sample some windows from this background activity class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2687d000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_background_activity_class(data: np.array, labels: np.array, sz: int):\n",
    "    \"\"\"\n",
    "    Removes most samples from the dominant background activity class, down to a sample size (sz) specified in this function.  \n",
    "    \"\"\"\n",
    "    # Identify indices of the noise class and signal class\n",
    "    noise_idx = np.where(labels == 0)[0]\n",
    "    signal_idx = np.where(labels != 0)[0]\n",
    "\n",
    "    # Choose a sample from the noise class\n",
    "    sample_idx = np.random.choice(noise_idx, size = sz, replace=False)\n",
    "\n",
    "    # Combine the sampled indices with the other class indices\n",
    "    combined_idx = np.concatenate([signal_idx, sample_idx])\n",
    "    combined_idx = np.random.permutation(combined_idx)\n",
    "\n",
    "    # Apply the indexes to the data and labels\n",
    "    data_sample = data[combined_idx, :, :]\n",
    "    labels_sample = labels[combined_idx]\n",
    "    \n",
    "    return data_sample, labels_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f720c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train, ys_train = sample_background_activity_class(data = x_train, labels = y_train, sz = 150)\n",
    "xs_val, ys_val = sample_background_activity_class(data = x_val, labels = y_val, sz = 40)\n",
    "xs_test, ys_test = sample_background_activity_class(data = x_test, labels = y_test, sz = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed7e8e4",
   "metadata": {},
   "source": [
    "## Save datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239d5b36",
   "metadata": {},
   "source": [
    "We save the sampled datasets to train, validation and test files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9da4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train.npy', 'wb') as f:\n",
    "    np.save(f, xs_train)\n",
    "    np.save(f, ys_train)\n",
    "    \n",
    "with open('data/val.npy', 'wb') as f:\n",
    "    np.save(f, xs_val)\n",
    "    np.save(f, ys_val)\n",
    "    \n",
    "with open('data/test.npy', 'wb') as f:\n",
    "    np.save(f, xs_test)\n",
    "    np.save(f, ys_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac88cd0",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c717f",
   "metadata": {},
   "source": [
    "#### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d82eaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activity_counts(y_train, y_val, y_test):\n",
    "    train_labels, train_counts = np.unique(y_train, return_counts = True)\n",
    "    val_labels, val_counts = np.unique(y_val, return_counts = True)\n",
    "    test_labels, test_counts = np.unique(y_test, return_counts = True)\n",
    "\n",
    "    train_label_counts = pd.DataFrame(np.hstack([train_labels[:, np.newaxis], train_counts[:, np.newaxis]]), columns = [\"Label\", \"Train Count\"])\n",
    "    val_label_counts = pd.DataFrame(np.hstack([val_labels[:, np.newaxis], val_counts[:, np.newaxis]]), columns = [\"Label\", \"Val Count\"])\n",
    "    test_label_counts = pd.DataFrame(np.hstack([test_labels[:, np.newaxis], test_counts[:, np.newaxis]]), columns = [\"Label\", \"Test Count\"])\n",
    "    \n",
    "    label_counts = train_label_counts.merge(val_label_counts, how = \"outer\", on = \"Label\").merge(test_label_counts, how = \"outer\", on = \"Label\")\n",
    "    label_counts[\"Label\"] = label_counts[\"Label\"].map(ACTIVITY_MAPPING)\n",
    "    label_counts = label_counts.set_index(\"Label\")\n",
    "    label_counts = label_counts.sort_values([\"Train Count\"], ascending=[False])\n",
    "    \n",
    "    return label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db978710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Count</th>\n",
       "      <th>Val Count</th>\n",
       "      <th>Test Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No activity identified</th>\n",
       "      <td>14665.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>3573.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Front Dumbbell Raise</th>\n",
       "      <td>167.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dumbbell Alternate Bicep Curl</th>\n",
       "      <td>167.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dumbbell Flyes</th>\n",
       "      <td>160.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incline Dumbbell Flyes</th>\n",
       "      <td>143.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hammer Curl</th>\n",
       "      <td>127.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incline Dumbbell Press</th>\n",
       "      <td>123.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spider Curl</th>\n",
       "      <td>120.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wide-Grip Pulldown Behind The Neck</th>\n",
       "      <td>112.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wide-Grip Front Pulldown</th>\n",
       "      <td>109.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incline Hammer Curl</th>\n",
       "      <td>105.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bar Skullcrusher</th>\n",
       "      <td>105.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seated Cable Rows</th>\n",
       "      <td>101.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concentration Curl</th>\n",
       "      <td>90.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leverage Chest Press</th>\n",
       "      <td>90.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seated Dumbbell Shoulder Press</th>\n",
       "      <td>89.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close-Grip Barbell Bench Press</th>\n",
       "      <td>89.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cable Curl</th>\n",
       "      <td>89.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Side Lateral Raise</th>\n",
       "      <td>85.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upright Barbell Row</th>\n",
       "      <td>85.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Arm Dumbbell Row</th>\n",
       "      <td>81.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Triceps Pushdown</th>\n",
       "      <td>79.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overhead Triceps Extension</th>\n",
       "      <td>78.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lying Rear Delt Raise</th>\n",
       "      <td>69.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bench Press</th>\n",
       "      <td>68.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car Drivers</th>\n",
       "      <td>63.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bench Dip / Dip</th>\n",
       "      <td>62.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bent Over Barbell Row</th>\n",
       "      <td>59.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tricep Dumbbell Kickback</th>\n",
       "      <td>58.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reverse Grip Bent-Over Row</th>\n",
       "      <td>57.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pushups</th>\n",
       "      <td>53.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Train Count  Val Count  Test Count\n",
       "Label                                                                 \n",
       "No activity identified                  14665.0     3436.0      3573.0\n",
       "Front Dumbbell Raise                      167.0       55.0        28.0\n",
       "Dumbbell Alternate Bicep Curl             167.0       77.0        32.0\n",
       "Dumbbell Flyes                            160.0       47.0        15.0\n",
       "Incline Dumbbell Flyes                    143.0       48.0        23.0\n",
       "Hammer Curl                               127.0       59.0        35.0\n",
       "Incline Dumbbell Press                    123.0       32.0        19.0\n",
       "Spider Curl                               120.0       31.0        25.0\n",
       "Wide-Grip Pulldown Behind The Neck        112.0       26.0        24.0\n",
       "Wide-Grip Front Pulldown                  109.0       27.0        10.0\n",
       "Incline Hammer Curl                       105.0       38.0        24.0\n",
       "Bar Skullcrusher                          105.0       35.0        31.0\n",
       "Seated Cable Rows                         101.0       34.0        19.0\n",
       "Concentration Curl                         90.0       32.0        13.0\n",
       "Leverage Chest Press                       90.0       24.0        19.0\n",
       "Seated Dumbbell Shoulder Press             89.0       29.0        13.0\n",
       "Close-Grip Barbell Bench Press             89.0       26.0         9.0\n",
       "Cable Curl                                 89.0       25.0        17.0\n",
       "Side Lateral Raise                         85.0       27.0        22.0\n",
       "Upright Barbell Row                        85.0       25.0        13.0\n",
       "One-Arm Dumbbell Row                       81.0       25.0        17.0\n",
       "Triceps Pushdown                           79.0       32.0        14.0\n",
       "Overhead Triceps Extension                 78.0       35.0        20.0\n",
       "Lying Rear Delt Raise                      69.0       24.0        22.0\n",
       "Bench Press                                68.0       23.0        17.0\n",
       "Car Drivers                                63.0        9.0        28.0\n",
       "Bench Dip / Dip                            62.0       27.0        20.0\n",
       "Bent Over Barbell Row                      59.0       14.0        12.0\n",
       "Tricep Dumbbell Kickback                   58.0       36.0        18.0\n",
       "Reverse Grip Bent-Over Row                 57.0       10.0        12.0\n",
       "Pushups                                    53.0       20.0         5.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = get_activity_counts(y_train, y_val, y_test)\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc6de9",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b96a7c",
   "metadata": {},
   "source": [
    "[1] Koskimäki, Heli, Pekka Siirtola and Juha Röning. “MyoGym: introducing an open gym data set for activity recognition collected using myo armband.” Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers (2017): n. pag."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
