{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8956138c",
   "metadata": {},
   "source": [
    "# Split data and prepare windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292dcc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocess.ipynb\n",
    "%run sys_configs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "980b09f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c62b8f",
   "metadata": {},
   "source": [
    "This notebook contains functions to split the MyoGym dataset into train, validation and test sets and compute windows from each time series data stream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fc5bd1",
   "metadata": {},
   "source": [
    "## Separate test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92de88",
   "metadata": {},
   "source": [
    "The data is split into train, validation and test data. In order to show our proposed methods extend to unseen trainers, the test dataset will contain the data for two trainers who do not feature in either the train or validation datasets. \n",
    "\n",
    "The train and validation datasets are not initially split out. They are split out after windowing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "132c0bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = data.index.get_level_values(\"trainer\").unique()\n",
    "shuffled_idx = np.random.permutation(idx)\n",
    "\n",
    "# Split into a combined train/validation dataset and a test dataset\n",
    "comb_idxs = shuffled_idx[:8] # First 8 trainers\n",
    "test_idxs = shuffled_idx[8:] # Last 2 trainers\n",
    "\n",
    "# Create the 2 datasets.\n",
    "comb = data.loc[comb_idxs]\n",
    "test = data.loc[test_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c24515f",
   "metadata": {},
   "source": [
    "## Define and apply windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff810af",
   "metadata": {},
   "source": [
    "There are two windowing techniques we will deploy for GAR tasks; \n",
    "\n",
    "- Window technique 1: incorporates only a fixed number of the most recent observations, if there is no activity changepoint in the window.\n",
    "- Window technique 2: incorporates all time steps from the beginning of the time series for an activity up to the current time step, until the minimum of:\n",
    "    - the end of the time series for that activity or;\n",
    "    - a maximum time series length\n",
    "\n",
    "Window technique 1 is used for the benchmark methods, while window technique 2 is used for methods in this work which incorporate historical information. Window technique 1 is implemented as a precomputed Numpy matrix, while window technique 2 is implemented as a generator owing to its size. Pictorial representations of each windowing technique are shown below.\n",
    "\n",
    "Note that both window techniques break on reaching an activity changepoint. Every window is designed to map to a single class. There are no fuzzy classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a653965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_method_1(data, sz = 250, step = 50):\n",
    "    \"\"\"\n",
    "    Computes windows for each time series stream. \n",
    "    If there is a label change in the window then the entire window is discarded.\n",
    "    We seek windows which have unambiguous non-conflicting class labels.\n",
    "    \"\"\"\n",
    "    # Create a mask for where the activity changes.\n",
    "    data[\"activity_mask\"] = data['activity'].ne(data['activity'].shift())\n",
    "       \n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for t in data.index.get_level_values('trainer').unique():\n",
    "        # Get all the data for this trainer\n",
    "        trainer_data = data.loc[data.index.get_level_values('trainer') == t]\n",
    "        \n",
    "        # Obtain a list of all windows\n",
    "        for start in range(0, len(trainer_data) - sz + 1, step):\n",
    "            # Filter for the current window\n",
    "            window = trainer_data.iloc[start:start + sz]\n",
    "            \n",
    "            if window.isna().values.any():\n",
    "                # Skip windows with NaN values (the first and last few windows)\n",
    "                continue\n",
    "            \n",
    "            if window.loc[:, \"activity_mask\"].values.any():\n",
    "                # Skip windows where the activity changes during that window\n",
    "                continue\n",
    "            \n",
    "            window_data = window.loc[:, [\"acc_x\", \"acc_y\", \"acc_z\", \"gyr_x\", \"gyr_y\", \"gyr_z\"]]\n",
    "            window_label = window.loc[:, \"activity\"].unique()[0]\n",
    "            \n",
    "            data_list.append(window_data)\n",
    "            label_list.append(window_label)\n",
    "            \n",
    "    # Conver to Numpy arrays\n",
    "    data_np = np.array(data_list)\n",
    "    label_np = np.array(label_list)\n",
    "    \n",
    "    return data_np, label_np            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67f9544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_comb, y1_comb = window_method_1(comb, sz = 500, step = 50)\n",
    "x1_test, y1_test = window_method_1(test, sz = 500, step = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87938f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Method 1 (Train/Validation): There are 21927 samples of window length 500 and dimensionality 6.\n",
      "Window Method 1 (Test): There are 4141 samples of window length 500 and dimensionality 6.\n"
     ]
    }
   ],
   "source": [
    "print(\"Window Method 1 (Train/Validation): There are %s samples of window length %s and dimensionality %s.\" % (x1_comb.shape))\n",
    "print(\"Window Method 1 (Test): There are %s samples of window length %s and dimensionality %s.\" % (x1_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149cb19c",
   "metadata": {},
   "source": [
    "## Separate validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598e9d5e",
   "metadata": {},
   "source": [
    "The combined (train, validation) data is now split into separate train and validation datasets. The validation dataset is taken from the same trainers as the train data. In most contexts involving time series, the test dataset is temporally separated from the train dataset. In both window methods, we consider windows to be independent, i.e. we can ignore any autocorrelation that might have preceded the division into windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8fd531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_val, y1_train, y1_val = train_test_split(x1_comb, y1_comb, test_size=0.125, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe214249",
   "metadata": {},
   "source": [
    "## Data normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf71f80",
   "metadata": {},
   "source": [
    "Data normalisation is essential to the process of adjusting all channels to an identical range. Many time series classification techniques that we will study, for example Dynamic Time Warping, use distance metrics that depend on each dimension having the same scale. We will use sklearn's StandardScalar.\n",
    "\n",
    "The use of a standard scaling allows us to more easily identify outliers and to more rigorously quantify the extent of these outliers using hypothesis tests of a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a4528c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "N1_train, T , D = x1_train.shape\n",
    "N1_val, _ , _ = x1_val.shape\n",
    "N1_test, _ , _ = x1_test.shape\n",
    "\n",
    "# Standard scaler works only for 2 dimensional data, so we melt the time dimension into the sample dimension\n",
    "x1_train = x1_train.reshape(N1_train * T, D)\n",
    "x1_val = x1_val.reshape(N1_val * T, D)\n",
    "x1_test = x1_test.reshape(N1_test * T, D)\n",
    "\n",
    "# Fit the standard scaler to the train data, then transform the validation and test data\n",
    "x1_train = scaler.fit_transform(x1_train)\n",
    "x1_val = scaler.transform(x1_val)\n",
    "x1_test = scaler.transform(x1_test)\n",
    "\n",
    "# Transform back to the N X T X D shape\n",
    "x1_train = x1_train.reshape(N1_train, T, D)\n",
    "x1_val = x1_val.reshape(N1_val, T, D)\n",
    "x1_test = x1_test.reshape(N1_test, T, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36e3e5",
   "metadata": {},
   "source": [
    "## Sample background activity class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6cabf1",
   "metadata": {},
   "source": [
    "According to the paper [1] which introduced the MyoGym dataset, the background activity class, which it describes as the null class, accounts for 77% of the dataset, a number which dwarves the remaining 30 classes. Most of the techniques we explore are sensitive to class imbalanaces or to dataset sizes. Therefore, we sample some windows from this background activity class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d66f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_counts = np.unique(y1_train, return_counts = True)\n",
    "val_labels, val_counts = np.unique(y1_val, return_counts = True)\n",
    "test_labels, test_counts = np.unique(y1_test, return_counts = True)\n",
    "\n",
    "train_label_counts = pd.DataFrame(np.hstack([train_labels[:, np.newaxis], train_counts[:, np.newaxis]]), columns = [\"Label\", \"Train Count\"])\n",
    "val_label_counts = pd.DataFrame(np.hstack([val_labels[:, np.newaxis], val_counts[:, np.newaxis]]), columns = [\"Label\", \"Val Count\"])\n",
    "test_label_counts = pd.DataFrame(np.hstack([test_labels[:, np.newaxis], test_counts[:, np.newaxis]]), columns = [\"Label\", \"Test Count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f553b66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Count</th>\n",
       "      <th>Test Count</th>\n",
       "      <th>Val Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No activity identified</th>\n",
       "      <td>15833</td>\n",
       "      <td>3566</td>\n",
       "      <td>2261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dumbbell Alternate Bicep Curl</th>\n",
       "      <td>221</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Front Dumbbell Raise</th>\n",
       "      <td>195</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dumbbell Flyes</th>\n",
       "      <td>174</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hammer Curl</th>\n",
       "      <td>166</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incline Dumbbell Flyes</th>\n",
       "      <td>161</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spider Curl</th>\n",
       "      <td>141</td>\n",
       "      <td>24</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incline Dumbbell Press</th>\n",
       "      <td>136</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Incline Hammer Curl</th>\n",
       "      <td>124</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bar Skullcrusher</th>\n",
       "      <td>122</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wide-Grip Pulldown Behind The Neck</th>\n",
       "      <td>122</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wide-Grip Front Pulldown</th>\n",
       "      <td>118</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seated Cable Rows</th>\n",
       "      <td>109</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concentration Curl</th>\n",
       "      <td>107</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seated Dumbbell Shoulder Press</th>\n",
       "      <td>102</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cable Curl</th>\n",
       "      <td>99</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overhead Triceps Extension</th>\n",
       "      <td>99</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Triceps Pushdown</th>\n",
       "      <td>99</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close-Grip Barbell Bench Press</th>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leverage Chest Press</th>\n",
       "      <td>97</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Side Lateral Raise</th>\n",
       "      <td>96</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>One-Arm Dumbbell Row</th>\n",
       "      <td>96</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upright Barbell Row</th>\n",
       "      <td>95</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lying Rear Delt Raise</th>\n",
       "      <td>86</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tricep Dumbbell Kickback</th>\n",
       "      <td>80</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bench Press</th>\n",
       "      <td>79</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bench Dip / Dip</th>\n",
       "      <td>77</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bent Over Barbell Row</th>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pushups</th>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car Drivers</th>\n",
       "      <td>63</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reverse Grip Bent-Over Row</th>\n",
       "      <td>59</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Train Count  Test Count  Val Count\n",
       "Label                                                                 \n",
       "No activity identified                    15833        3566       2261\n",
       "Dumbbell Alternate Bicep Curl               221          31         23\n",
       "Front Dumbbell Raise                        195          27         28\n",
       "Dumbbell Flyes                              174          14         31\n",
       "Hammer Curl                                 166          36         18\n",
       "Incline Dumbbell Flyes                      161          23         29\n",
       "Spider Curl                                 141          24         13\n",
       "Incline Dumbbell Press                      136          19         18\n",
       "Incline Hammer Curl                         124          24         21\n",
       "Bar Skullcrusher                            122          30         19\n",
       "Wide-Grip Pulldown Behind The Neck          122          25         16\n",
       "Wide-Grip Front Pulldown                    118           9         18\n",
       "Seated Cable Rows                           109          20         24\n",
       "Concentration Curl                          107          13         13\n",
       "Seated Dumbbell Shoulder Press              102          13         17\n",
       "Cable Curl                                   99          18         17\n",
       "Overhead Triceps Extension                   99          20         14\n",
       "Triceps Pushdown                             99          14         12\n",
       "Close-Grip Barbell Bench Press               98           9         16\n",
       "Leverage Chest Press                         97          19         17\n",
       "Side Lateral Raise                           96          23         15\n",
       "One-Arm Dumbbell Row                         96          16          9\n",
       "Upright Barbell Row                          95          14         15\n",
       "Lying Rear Delt Raise                        86          22          7\n",
       "Tricep Dumbbell Kickback                     80          17         17\n",
       "Bench Press                                  79          17         10\n",
       "Bench Dip / Dip                              77          21         12\n",
       "Bent Over Barbell Row                        69          12          3\n",
       "Pushups                                      63           4         10\n",
       "Car Drivers                                  63          28          8\n",
       "Reverse Grip Bent-Over Row                   59          13         10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = train_label_counts.merge(test_label_counts, on = \"Label\").merge(val_label_counts, on = \"Label\")\n",
    "label_counts[\"Label\"] = label_counts[\"Label\"].map(ACTIVITY_MAPPING)\n",
    "label_counts = label_counts.set_index(\"Label\")\n",
    "label_counts.sort_values([\"Train Count\"], ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91a862ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_noise_class(data: np.array, labels: np.array, sz: int):\n",
    "    \"\"\"\n",
    "    Removes most samples from the dominant noise class, down to a sample size (sz) specified in this function.  \n",
    "    \"\"\"\n",
    "    # Identify indices of the noise class and signal class\n",
    "    noise_idx = np.where(labels == 99)[0]\n",
    "    signal_idx = np.where(labels != 99)[0]\n",
    "\n",
    "    # Choose a sample from the noise class\n",
    "    sample_idx = np.random.choice(noise_idx, size = sz, replace=False)\n",
    "\n",
    "    # Combine the sampled indices with the other class indices\n",
    "    combined_idx = np.concatenate([signal_idx, sample_idx])\n",
    "\n",
    "    # Apply the indexes to the data and labels\n",
    "    data_sample = x1_train[combined_idx, :, :]\n",
    "    labels_sample = labels[combined_idx]\n",
    "    \n",
    "    return data_sample, labels_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "556b75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1s_train, y1s_train = sample_noise_class(data = x1_train, labels = y1_train, sz = 250)\n",
    "x1s_val, y1s_val = sample_noise_class(data = x1_val, labels = y1_val, sz = 50)\n",
    "x1s_test, y1s_test = sample_noise_class(data = x1_test, labels = y1_test, sz = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ddc03c",
   "metadata": {},
   "source": [
    "## Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3681f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/1s_train.npy', 'wb') as f:\n",
    "    np.save(f, x1s_train)\n",
    "    np.save(f, y1s_train)\n",
    "    \n",
    "with open('data/1s_val.npy', 'wb') as f:\n",
    "    np.save(f, x1s_val)\n",
    "    np.save(f, y1s_val)\n",
    "    \n",
    "with open('data/1s_test.npy', 'wb') as f:\n",
    "    np.save(f, x1s_test)\n",
    "    np.save(f, y1s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a38e07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/1_train.npy', 'wb') as f:\n",
    "    np.save(f, x1_train)\n",
    "    np.save(f, y1_train)\n",
    "\n",
    "with open('data/1_val.npy', 'wb') as f:\n",
    "    np.save(f, x1_val)\n",
    "    np.save(f, y1_val)\n",
    "    \n",
    "with open('data/1_test.npy', 'wb') as f:\n",
    "    np.save(f, x1_test)\n",
    "    np.save(f, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c8563e",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b6e8f0",
   "metadata": {},
   "source": [
    "[1] Koskimäki, Heli, Pekka Siirtola and Juha Röning. “MyoGym: introducing an open gym data set for activity recognition collected using myo armband.” Proceedings of the 2017 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2017 ACM International Symposium on Wearable Computers (2017): n. pag."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
