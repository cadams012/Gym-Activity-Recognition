{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc057d7",
   "metadata": {
    "id": "dcc057d7"
   },
   "source": [
    "# **Exploring Rocket Losses**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MUJr2MK1cTLd",
   "metadata": {
    "id": "MUJr2MK1cTLd"
   },
   "source": [
    "When training the Rocket architecture, it was noticed the accuracy reached very high levels but that this was not commensurate with the magnitude of the loss function. We explore why in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nUB3qukkVz4e",
   "metadata": {
    "id": "nUB3qukkVz4e"
   },
   "source": [
    "## **Initialisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Rnoi2AD9umez",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rnoi2AD9umez",
    "outputId": "3b6d7ffe-d36f-4da6-ec0a-b72a1b4dbbd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sktime==0.32.1 in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
      "Requirement already satisfied: joblib<1.5,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from sktime==0.32.1) (1.4.2)\n",
      "Requirement already satisfied: numpy<2.1,>=1.21 in /usr/local/lib/python3.10/dist-packages (from sktime==0.32.1) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sktime==0.32.1) (24.1)\n",
      "Requirement already satisfied: pandas<2.3.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from sktime==0.32.1) (2.1.4)\n",
      "Requirement already satisfied: scikit-base<0.9.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from sktime==0.32.1) (0.8.3)\n",
      "Requirement already satisfied: scikit-learn<1.6.0,>=0.24 in /usr/local/lib/python3.10/dist-packages (from sktime==0.32.1) (1.3.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from sktime==0.32.1) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.1->sktime==0.32.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.1->sktime==0.32.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.1->sktime==0.32.1) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.6.0,>=0.24->sktime==0.32.1) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=1.1->sktime==0.32.1) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "pip install sktime==0.32.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8R9a8pMzlk17",
   "metadata": {
    "id": "8R9a8pMzlk17"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sktime.transformations.panel.rocket import MiniRocketMultivariate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import L1, L2\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.layers import Input, Layer, Conv1D, MaxPool1D, ReLU, BatchNormalization, LayerNormalization, Dropout, Add, Dense, GlobalMaxPooling1D, Bidirectional, GRU, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6PHiGpI9_k54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PHiGpI9_k54",
    "outputId": "bd62b28e-0b4b-433f-d867-92955fc7c3d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#You MUST run this command before reading in any data from Google Drive\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "import pandas as pd\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "os.chdir('/content/drive/My Drive/Colab Notebooks/Thesis/experiments')\n",
    "\n",
    "%run ../sys_configs.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "Ug5PdJ8i_k_7",
   "metadata": {
    "id": "Ug5PdJ8i_k_7"
   },
   "outputs": [],
   "source": [
    "with open('../data/train.npy', 'rb') as f:\n",
    "    x_train = np.load(f)\n",
    "    y_train = np.load(f).astype(np.int64)\n",
    "sz, dim = x_train.shape[1:]\n",
    "\n",
    "with open('../data/val.npy', 'rb') as f:\n",
    "    x_val = np.load(f)\n",
    "    y_val = np.load(f).astype(np.int64)\n",
    "\n",
    "with open('../data/test.npy', 'rb') as f:\n",
    "    x_test = np.load(f)\n",
    "    y_test = np.load(f).astype(np.int64)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "N_train = len(y_train)\n",
    "N_val = len(y_val)\n",
    "N_test = len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ZwDmf0p1_lCz",
   "metadata": {
    "id": "ZwDmf0p1_lCz"
   },
   "outputs": [],
   "source": [
    "# Convert the labels to tensors\n",
    "train_labels_tf = tf.one_hot(y_train, 31, dtype=tf.float32)\n",
    "val_labels_tf = tf.one_hot(y_val, 31, dtype=tf.float32)\n",
    "test_labels_tf = tf.one_hot(y_test, 31, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ov_Y-qXHWIpd",
   "metadata": {
    "id": "Ov_Y-qXHWIpd"
   },
   "source": [
    "#### **Prepare Rocket transformation train & validation datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Pd8qFYGASmxg",
   "metadata": {
    "id": "Pd8qFYGASmxg"
   },
   "outputs": [],
   "source": [
    "# Transpose the train and validation data as the format needs to be N x D x T\n",
    "x_train_ = x_train.transpose((0, 2, 1))\n",
    "x_val_ = x_val.transpose((0, 2, 1))\n",
    "x_test_ = x_test.transpose((0, 2, 1))\n",
    "\n",
    "# Compute the MiniRocket transform and transform to tensors\n",
    "minirocket_multi = MiniRocketMultivariate(num_kernels = 10000, max_dilations_per_kernel = 32)\n",
    "minirocket_multi.fit(x_train_)\n",
    "\n",
    "train_rocket_np = minirocket_multi.transform(x_train_).to_numpy()\n",
    "val_rocket_np = minirocket_multi.transform(x_val_).to_numpy()\n",
    "test_rocket_np = minirocket_multi.transform(x_test_).to_numpy()\n",
    "\n",
    "train_rocket_tf = tf.convert_to_tensor(train_rocket_np, dtype = tf.float32)\n",
    "val_rocket_tf = tf.convert_to_tensor(val_rocket_np, dtype = tf.float32)\n",
    "test_rocket_tf = tf.convert_to_tensor(test_rocket_np, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mnSFpMMnVrH8",
   "metadata": {
    "id": "mnSFpMMnVrH8"
   },
   "outputs": [],
   "source": [
    "train_rocket_ds = tf.data.Dataset.from_tensor_slices((train_rocket_tf, train_labels_tf))\n",
    "val_rocket_ds = tf.data.Dataset.from_tensor_slices((val_rocket_tf, val_labels_tf))\n",
    "test_rocket_ds = tf.data.Dataset.from_tensor_slices((test_rocket_tf, test_labels_tf))\n",
    "\n",
    "train_rocket_ds = train_rocket_ds.shuffle(500)\n",
    "\n",
    "train_rocket_ds = train_rocket_ds.padded_batch(64)\n",
    "val_rocket_ds = val_rocket_ds.padded_batch(64)\n",
    "test_rocket_ds = test_rocket_ds.padded_batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "p78kXUqdMnX6",
   "metadata": {
    "id": "p78kXUqdMnX6"
   },
   "outputs": [],
   "source": [
    "C = len(set(y_train)) # Number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CjU_-c8QM0oM",
   "metadata": {
    "id": "CjU_-c8QM0oM"
   },
   "source": [
    "## **Experiment: Rocket transformation with *sktime* implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "G8nOMQlpeOMS",
   "metadata": {
    "id": "G8nOMQlpeOMS"
   },
   "outputs": [],
   "source": [
    "def RocketSktime(shape):\n",
    "    block1_input_layer = Input(shape=shape)\n",
    "    output_layer = Dense(C, activation=\"softmax\")(block1_input_layer) #, kernel_regularizer = l2(10)\n",
    "    return Model(inputs=block1_input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "zr_jvH1VVd4Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "id": "zr_jvH1VVd4Z",
    "outputId": "235746db-b3b4-41f9-eba3-978114e93e73"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9996</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">309,907</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9996\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)                  │         \u001b[38;5;34m309,907\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">309,907</span> (1.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m309,907\u001b[0m (1.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">309,907</span> (1.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m309,907\u001b[0m (1.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rocketsktime = RocketSktime(shape = (9996,))\n",
    "rocketsktime.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "WAerHo25Uhw4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAerHo25Uhw4",
    "outputId": "038735b6-e3f6-4e81-b052-f868a6a39679"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.0443 - loss: 16338.2207 - val_accuracy: 0.0704 - val_loss: 10820.7227\n",
      "Epoch 2/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.1075 - loss: 10465.8789 - val_accuracy: 0.1473 - val_loss: 8340.1836\n",
      "Epoch 3/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.1904 - loss: 6839.5840 - val_accuracy: 0.2227 - val_loss: 4946.8486\n",
      "Epoch 4/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.2573 - loss: 4339.7529 - val_accuracy: 0.3032 - val_loss: 2546.4197\n",
      "Epoch 5/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3286 - loss: 2433.9175 - val_accuracy: 0.3843 - val_loss: 1802.1234\n",
      "Epoch 6/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4012 - loss: 1419.4506 - val_accuracy: 0.5036 - val_loss: 1095.6503\n",
      "Epoch 7/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5343 - loss: 743.7344 - val_accuracy: 0.4447 - val_loss: 867.6376\n",
      "Epoch 8/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.5638 - loss: 627.0597 - val_accuracy: 0.5489 - val_loss: 611.3535\n",
      "Epoch 9/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6567 - loss: 416.6840 - val_accuracy: 0.5697 - val_loss: 556.9207\n",
      "Epoch 10/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6957 - loss: 291.1132 - val_accuracy: 0.5754 - val_loss: 552.7369\n",
      "Epoch 11/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.7564 - loss: 174.5378 - val_accuracy: 0.6006 - val_loss: 481.5510\n",
      "Epoch 12/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8044 - loss: 143.8464 - val_accuracy: 0.6049 - val_loss: 488.8823\n",
      "Epoch 13/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8227 - loss: 127.2299 - val_accuracy: 0.6243 - val_loss: 446.9654\n",
      "Epoch 14/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7934 - loss: 180.6506 - val_accuracy: 0.5999 - val_loss: 536.7624\n",
      "Epoch 15/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8209 - loss: 144.3561 - val_accuracy: 0.6185 - val_loss: 408.2043\n",
      "Epoch 16/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8501 - loss: 90.0350 - val_accuracy: 0.6559 - val_loss: 333.1003\n",
      "Epoch 17/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8428 - loss: 104.0992 - val_accuracy: 0.6408 - val_loss: 337.1729\n",
      "Epoch 18/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8823 - loss: 65.1176 - val_accuracy: 0.6358 - val_loss: 374.4834\n",
      "Epoch 19/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.8550 - loss: 90.1373 - val_accuracy: 0.6300 - val_loss: 389.5984\n",
      "Epoch 20/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8716 - loss: 69.2990 - val_accuracy: 0.6358 - val_loss: 358.9878\n",
      "Epoch 21/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8664 - loss: 91.8974 - val_accuracy: 0.6401 - val_loss: 395.2864\n",
      "Epoch 22/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8664 - loss: 72.8080 - val_accuracy: 0.6386 - val_loss: 378.6878\n",
      "Epoch 23/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8726 - loss: 86.2965 - val_accuracy: 0.6351 - val_loss: 325.0174\n",
      "Epoch 24/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.8759 - loss: 64.5840 - val_accuracy: 0.6049 - val_loss: 353.1185\n",
      "Epoch 25/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8860 - loss: 61.1427 - val_accuracy: 0.6408 - val_loss: 337.1247\n",
      "Epoch 26/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9147 - loss: 40.9388 - val_accuracy: 0.6149 - val_loss: 381.8404\n",
      "Epoch 27/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8997 - loss: 49.9216 - val_accuracy: 0.7047 - val_loss: 301.0679\n",
      "Epoch 28/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9118 - loss: 48.9733 - val_accuracy: 0.6616 - val_loss: 346.1095\n",
      "Epoch 29/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8935 - loss: 94.4133 - val_accuracy: 0.6501 - val_loss: 352.1927\n",
      "Epoch 30/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9082 - loss: 48.7113 - val_accuracy: 0.6509 - val_loss: 301.0515\n",
      "Epoch 31/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8977 - loss: 55.5093 - val_accuracy: 0.6731 - val_loss: 317.2536\n",
      "Epoch 32/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9019 - loss: 57.6921 - val_accuracy: 0.6681 - val_loss: 353.9553\n",
      "Epoch 33/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9151 - loss: 61.0449 - val_accuracy: 0.6983 - val_loss: 314.8138\n",
      "Epoch 34/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9148 - loss: 56.0154 - val_accuracy: 0.6078 - val_loss: 481.6015\n",
      "Epoch 35/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9055 - loss: 69.5866 - val_accuracy: 0.6868 - val_loss: 286.4414\n",
      "Epoch 36/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8967 - loss: 60.7429 - val_accuracy: 0.6724 - val_loss: 326.6350\n",
      "Epoch 37/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8859 - loss: 62.5748 - val_accuracy: 0.6897 - val_loss: 356.9966\n",
      "Epoch 38/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8761 - loss: 128.8816 - val_accuracy: 0.6430 - val_loss: 422.6188\n",
      "Epoch 39/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8945 - loss: 70.5280 - val_accuracy: 0.7004 - val_loss: 361.5003\n",
      "Epoch 40/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9146 - loss: 62.2969 - val_accuracy: 0.6537 - val_loss: 498.9620\n",
      "Epoch 41/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9255 - loss: 96.2475 - val_accuracy: 0.6875 - val_loss: 371.8936\n",
      "Epoch 42/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8938 - loss: 126.3307 - val_accuracy: 0.6193 - val_loss: 593.2720\n",
      "Epoch 43/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8854 - loss: 123.3887 - val_accuracy: 0.6236 - val_loss: 486.3702\n",
      "Epoch 44/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8740 - loss: 110.2241 - val_accuracy: 0.6652 - val_loss: 399.7103\n",
      "Epoch 45/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8772 - loss: 95.7951 - val_accuracy: 0.6444 - val_loss: 584.0829\n",
      "Epoch 46/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8617 - loss: 158.4772 - val_accuracy: 0.5833 - val_loss: 706.4713\n",
      "Epoch 47/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8531 - loss: 140.3366 - val_accuracy: 0.6135 - val_loss: 557.4517\n",
      "Epoch 48/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8795 - loss: 112.6390 - val_accuracy: 0.6552 - val_loss: 533.1237\n",
      "Epoch 49/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9122 - loss: 73.0855 - val_accuracy: 0.6351 - val_loss: 541.3245\n",
      "Epoch 50/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8888 - loss: 115.8174 - val_accuracy: 0.5876 - val_loss: 615.0920\n"
     ]
    }
   ],
   "source": [
    "rocketsktime_model = RocketSktime(shape = (9996,))\n",
    "rocketsktime_model.compile(optimizer=Adam(learning_rate=1.0, beta_1=0.99, beta_2=0.999, epsilon=1e-08), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_sktime = rocketsktime_model.fit(train_rocket_ds, validation_data=val_rocket_ds, epochs=50, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kpP0FbnOd90m",
   "metadata": {
    "id": "kpP0FbnOd90m"
   },
   "source": [
    "## **Extract predictions & targets to CSV**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8sLOzxtpi0Mz",
   "metadata": {
    "id": "8sLOzxtpi0Mz"
   },
   "source": [
    "Make predictions based on the validation data, then compute the sample-wise categorical cross entropy loss which will be useful for observing which samples contribute the most to the overall loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "UBf1RuaKeWH9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UBf1RuaKeWH9",
    "outputId": "383cf29e-506d-4277-cd5c-ba84c8012fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions based on the validation data\n",
    "val_preds_tf = rocketsktime_model.predict(val_rocket_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "-H9OJVhyjUGl",
   "metadata": {
    "id": "-H9OJVhyjUGl"
   },
   "outputs": [],
   "source": [
    "# Compute the sample-wise categorical cross entropy loss\n",
    "cce = CategoricalCrossentropy(reduction = None) # Using None reduction type to get a sample-wise Categorical Cross Entropy loss\n",
    "categorical_crossentropy = pd.DataFrame(cce(val_labels_tf, val_preds_tf).numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dMpdRe2ceeeu",
   "metadata": {
    "id": "dMpdRe2ceeeu"
   },
   "source": [
    "Get the index of the target and prediction and concatenate to their respective datasets. Then concatenate both datasets and the categorical cross entropy loss column and export to CSV for offline analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rfjGVqBYjId3",
   "metadata": {
    "id": "rfjGVqBYjId3"
   },
   "outputs": [],
   "source": [
    "val_labels_np = tf.argmax(val_labels_tf, axis = 1).numpy().reshape(-1, 1)\n",
    "val_preds_np = tf.argmax(val_preds_tf, axis = 1).numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dtRjm7bf2bR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dtRjm7bf2bR",
    "outputId": "33c0bd2d-0570-4965-9c6a-2f70d9bd53f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of val_labels is (1392, 32) and the shape of val_preds is (1392, 32)\n"
     ]
    }
   ],
   "source": [
    "val_labels = pd.DataFrame(np.hstack([val_labels_tf.numpy(), val_labels_np.reshape(-1, 1)]))\n",
    "val_preds = pd.DataFrame(np.hstack([val_preds_tf, val_preds_np.reshape(-1, 1)]))\n",
    "print(f\"The shape of val_labels is {val_labels.shape} and the shape of val_preds is {val_preds.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "r27DHQyBgi7H",
   "metadata": {
    "id": "r27DHQyBgi7H"
   },
   "outputs": [],
   "source": [
    "val_labels = val_labels.add_prefix('Labels_')\n",
    "val_preds = val_preds.add_prefix('Predictions_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dso8ueKTgo6F",
   "metadata": {
    "id": "dso8ueKTgo6F"
   },
   "outputs": [],
   "source": [
    "val_labels_and_preds = pd.concat([val_labels, val_preds, categorical_crossentropy], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ugHhCr-Sl5Ms",
   "metadata": {
    "id": "ugHhCr-Sl5Ms"
   },
   "source": [
    "The dataset has:\n",
    "- Predicted classes: 31 classes + 1 final prediction column\n",
    "- Target classes: 31 classes + 1 target column\n",
    "- Categorical cross entropy loss\n",
    "\n",
    "Therefore there are 65 columns overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YiNwfqMZg9-0",
   "metadata": {
    "id": "YiNwfqMZg9-0"
   },
   "outputs": [],
   "source": [
    "val_labels_and_preds.to_csv(\"rocket_analysis.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Mh0maoeYoNNe",
   "metadata": {
    "id": "Mh0maoeYoNNe"
   },
   "source": [
    "Exploring the dataset extracted earlier, it is immediately obvious that the model is learning a perfect mathematical fit on the training data, i.e. that every sample is correctly classified with 100% probability. This is because there are (many) more features than samples. This is why the Rocket transform was failing when even minor regularisation penalties were applied.\n",
    "\n",
    "Despite this, the model generalises fairly well to validation data, but either perfectly classifies or perfectly missclassifies (all probability mass is focussed on a single, wrong class) each sample. When the sample is missclassified, the categorical cross entropy loss takes a large, consistent value.\n",
    "\n",
    "Almost every missclassified sample produced the same value in the categorical cross entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iEfGLHqam_kg",
   "metadata": {
    "id": "iEfGLHqam_kg"
   },
   "source": [
    "## **Experiment 2: Refine model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WGjwE1ej06qx",
   "metadata": {
    "id": "WGjwE1ej06qx"
   },
   "source": [
    "In this experiment, we attempt to learn a condensed representation of the Rocket transform using an extra dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "CG_EAC_Mg-Bw",
   "metadata": {
    "id": "CG_EAC_Mg-Bw"
   },
   "outputs": [],
   "source": [
    "def RocketSktime2(shape):\n",
    "    block1_input_layer = Input(shape=shape)\n",
    "    layer = Dense(64, activation = \"sigmoid\")(block1_input_layer)\n",
    "    output_layer = Dense(C, activation=\"softmax\")(layer)\n",
    "    return Model(inputs=block1_input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "LUJNuRGPsuIS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "LUJNuRGPsuIS",
    "outputId": "85a65dac-9631-40ec-b504-33dfbfaa45ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9996</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">639,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,015</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9996\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m639,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)                  │           \u001b[38;5;34m2,015\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">641,823</span> (2.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m641,823\u001b[0m (2.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">641,823</span> (2.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m641,823\u001b[0m (2.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rocketsktime2 = RocketSktime2(shape = (9996,))\n",
    "rocketsktime2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "xLj00W96syxc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLj00W96syxc",
    "outputId": "48ea0baa-0a86-425f-a7fb-6cdd52200847"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.0372 - loss: 3.5112 - val_accuracy: 0.0654 - val_loss: 3.4114\n",
      "Epoch 2/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0499 - loss: 3.4101 - val_accuracy: 0.0496 - val_loss: 3.4068\n",
      "Epoch 3/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0482 - loss: 3.4269 - val_accuracy: 0.0496 - val_loss: 3.4068\n",
      "Epoch 4/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0543 - loss: 3.4199 - val_accuracy: 0.0438 - val_loss: 3.4038\n",
      "Epoch 5/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0502 - loss: 3.4155 - val_accuracy: 0.0654 - val_loss: 3.4041\n",
      "Epoch 6/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.0496 - loss: 3.4139 - val_accuracy: 0.0654 - val_loss: 3.4040\n",
      "Epoch 7/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.0426 - loss: 3.4121 - val_accuracy: 0.0496 - val_loss: 3.4024\n",
      "Epoch 8/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0508 - loss: 3.4136 - val_accuracy: 0.0654 - val_loss: 3.4014\n",
      "Epoch 9/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0497 - loss: 3.4112 - val_accuracy: 0.0654 - val_loss: 3.4020\n",
      "Epoch 10/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0465 - loss: 3.4144 - val_accuracy: 0.0496 - val_loss: 3.4029\n",
      "Epoch 11/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0494 - loss: 3.4119 - val_accuracy: 0.0654 - val_loss: 3.4024\n",
      "Epoch 12/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0467 - loss: 3.4147 - val_accuracy: 0.0496 - val_loss: 3.4030\n",
      "Epoch 13/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0482 - loss: 3.4136 - val_accuracy: 0.0654 - val_loss: 3.4023\n",
      "Epoch 14/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0474 - loss: 3.4136 - val_accuracy: 0.0654 - val_loss: 3.4016\n",
      "Epoch 15/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.0475 - loss: 3.4111 - val_accuracy: 0.0496 - val_loss: 3.4022\n",
      "Epoch 16/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0519 - loss: 3.4104 - val_accuracy: 0.0496 - val_loss: 3.4027\n",
      "Epoch 17/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.0486 - loss: 3.4130 - val_accuracy: 0.0654 - val_loss: 3.4021\n",
      "Epoch 18/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0482 - loss: 3.4114 - val_accuracy: 0.0654 - val_loss: 3.4019\n",
      "Epoch 19/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.0477 - loss: 3.4149 - val_accuracy: 0.0496 - val_loss: 3.4019\n",
      "Epoch 20/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.0459 - loss: 3.4123 - val_accuracy: 0.0654 - val_loss: 3.4023\n",
      "Epoch 21/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.0486 - loss: 3.4078 - val_accuracy: 0.0654 - val_loss: 3.4019\n",
      "Epoch 22/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0511 - loss: 3.4113 - val_accuracy: 0.0654 - val_loss: 3.4022\n",
      "Epoch 23/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.0500 - loss: 3.4132 - val_accuracy: 0.0654 - val_loss: 3.4024\n",
      "Epoch 24/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.0483 - loss: 3.4105 - val_accuracy: 0.0496 - val_loss: 3.4023\n",
      "Epoch 25/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.0516 - loss: 3.4091 - val_accuracy: 0.0496 - val_loss: 3.4025\n",
      "Epoch 26/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0494 - loss: 3.4118 - val_accuracy: 0.0654 - val_loss: 3.4028\n",
      "Epoch 27/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0504 - loss: 3.4114 - val_accuracy: 0.0654 - val_loss: 3.4025\n",
      "Epoch 28/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0528 - loss: 3.4107 - val_accuracy: 0.0654 - val_loss: 3.4016\n",
      "Epoch 29/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0497 - loss: 3.4092 - val_accuracy: 0.0496 - val_loss: 3.4025\n",
      "Epoch 30/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0489 - loss: 3.4128 - val_accuracy: 0.0496 - val_loss: 3.4029\n",
      "Epoch 31/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0499 - loss: 3.4129 - val_accuracy: 0.0496 - val_loss: 3.4025\n",
      "Epoch 32/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.0445 - loss: 3.4100 - val_accuracy: 0.0496 - val_loss: 3.4025\n",
      "Epoch 33/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.0543 - loss: 3.4116 - val_accuracy: 0.0496 - val_loss: 3.4021\n",
      "Epoch 34/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.0492 - loss: 3.4135 - val_accuracy: 0.0654 - val_loss: 3.4017\n",
      "Epoch 35/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.0417 - loss: 3.4145 - val_accuracy: 0.0654 - val_loss: 3.4025\n",
      "Epoch 36/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0515 - loss: 3.4102 - val_accuracy: 0.0496 - val_loss: 3.4029\n",
      "Epoch 37/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0509 - loss: 3.4103 - val_accuracy: 0.0496 - val_loss: 3.4022\n",
      "Epoch 38/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0531 - loss: 3.4130 - val_accuracy: 0.0496 - val_loss: 3.4022\n",
      "Epoch 39/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0455 - loss: 3.4077 - val_accuracy: 0.0654 - val_loss: 3.4025\n",
      "Epoch 40/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0475 - loss: 3.4147 - val_accuracy: 0.0654 - val_loss: 3.4024\n",
      "Epoch 41/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0493 - loss: 3.4129 - val_accuracy: 0.0654 - val_loss: 3.4024\n",
      "Epoch 42/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.0519 - loss: 3.4104 - val_accuracy: 0.0654 - val_loss: 3.4020\n",
      "Epoch 43/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0506 - loss: 3.4107 - val_accuracy: 0.0496 - val_loss: 3.4025\n",
      "Epoch 44/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.0489 - loss: 3.4124 - val_accuracy: 0.0496 - val_loss: 3.4024\n",
      "Epoch 45/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0521 - loss: 3.4121 - val_accuracy: 0.0496 - val_loss: 3.4027\n",
      "Epoch 46/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0494 - loss: 3.4138 - val_accuracy: 0.0654 - val_loss: 3.4018\n",
      "Epoch 47/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0502 - loss: 3.4113 - val_accuracy: 0.0654 - val_loss: 3.4021\n",
      "Epoch 48/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.0477 - loss: 3.4105 - val_accuracy: 0.0496 - val_loss: 3.4026\n",
      "Epoch 49/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.0522 - loss: 3.4107 - val_accuracy: 0.0496 - val_loss: 3.4023\n",
      "Epoch 50/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.0500 - loss: 3.4132 - val_accuracy: 0.0654 - val_loss: 3.4021\n",
      "Epoch 51/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.0488 - loss: 3.4107 - val_accuracy: 0.0654 - val_loss: 3.4025\n",
      "Epoch 52/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.0487 - loss: 3.4141 - val_accuracy: 0.0654 - val_loss: 3.4021\n",
      "Epoch 53/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0469 - loss: 3.4138 - val_accuracy: 0.0496 - val_loss: 3.4022\n",
      "Epoch 54/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0535 - loss: 3.4116 - val_accuracy: 0.0496 - val_loss: 3.4025\n",
      "Epoch 55/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0495 - loss: 3.4109 - val_accuracy: 0.0654 - val_loss: 3.4027\n",
      "Epoch 56/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0504 - loss: 3.4133 - val_accuracy: 0.0654 - val_loss: 3.4021\n",
      "Epoch 57/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0470 - loss: 3.4139 - val_accuracy: 0.0496 - val_loss: 3.4022\n",
      "Epoch 58/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0494 - loss: 3.4110 - val_accuracy: 0.0654 - val_loss: 3.4024\n",
      "Epoch 59/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.0494 - loss: 3.4151 - val_accuracy: 0.0654 - val_loss: 3.4022\n",
      "Epoch 60/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.0494 - loss: 3.4138 - val_accuracy: 0.0654 - val_loss: 3.4024\n",
      "Epoch 61/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.0466 - loss: 3.4119 - val_accuracy: 0.0496 - val_loss: 3.4025\n",
      "Epoch 62/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0514 - loss: 3.4123 - val_accuracy: 0.0654 - val_loss: 3.4024\n",
      "Epoch 63/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0454 - loss: 3.4112 - val_accuracy: 0.0654 - val_loss: 3.4024\n",
      "Epoch 64/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0477 - loss: 3.4120 - val_accuracy: 0.0654 - val_loss: 3.4023\n",
      "Epoch 65/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0481 - loss: 3.4130 - val_accuracy: 0.0496 - val_loss: 3.4025\n",
      "Epoch 66/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0509 - loss: 3.4105 - val_accuracy: 0.0654 - val_loss: 3.4024\n",
      "Epoch 67/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0491 - loss: 3.4103 - val_accuracy: 0.0654 - val_loss: 3.4023\n",
      "Epoch 68/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.0444 - loss: 3.4119 - val_accuracy: 0.0496 - val_loss: 3.4028\n",
      "Epoch 69/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.0482 - loss: 3.4138 - val_accuracy: 0.0496 - val_loss: 3.4024\n",
      "Epoch 70/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0507 - loss: 3.4119 - val_accuracy: 0.0496 - val_loss: 3.4023\n",
      "Epoch 71/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0482 - loss: 3.4125 - val_accuracy: 0.0654 - val_loss: 3.4021\n",
      "Epoch 72/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0483 - loss: 3.4121 - val_accuracy: 0.0654 - val_loss: 3.4022\n",
      "Epoch 73/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0476 - loss: 3.4122 - val_accuracy: 0.0654 - val_loss: 3.4021\n",
      "Epoch 74/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0465 - loss: 3.4095 - val_accuracy: 0.0654 - val_loss: 3.4021\n",
      "Epoch 75/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0513 - loss: 3.4109 - val_accuracy: 0.0654 - val_loss: 3.4023\n",
      "Epoch 76/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0490 - loss: 3.4119 - val_accuracy: 0.0496 - val_loss: 3.4026\n",
      "Epoch 77/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0497 - loss: 3.4122 - val_accuracy: 0.0496 - val_loss: 3.4026\n",
      "Epoch 78/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.0476 - loss: 3.4129 - val_accuracy: 0.0654 - val_loss: 3.4025\n",
      "Epoch 79/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.0496 - loss: 3.4094 - val_accuracy: 0.0654 - val_loss: 3.4019\n",
      "Epoch 80/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.0500 - loss: 3.4140 - val_accuracy: 0.0654 - val_loss: 3.4023\n",
      "Epoch 81/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0472 - loss: 3.4109 - val_accuracy: 0.0496 - val_loss: 3.4025\n",
      "Epoch 82/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0486 - loss: 3.4130 - val_accuracy: 0.0654 - val_loss: 3.4024\n",
      "Epoch 83/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0481 - loss: 3.4130 - val_accuracy: 0.0654 - val_loss: 3.4020\n",
      "Epoch 84/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0459 - loss: 3.4129 - val_accuracy: 0.0496 - val_loss: 3.4024\n",
      "Epoch 85/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0497 - loss: 3.4111 - val_accuracy: 0.0496 - val_loss: 3.4024\n",
      "Epoch 86/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0518 - loss: 3.4140 - val_accuracy: 0.0654 - val_loss: 3.4021\n",
      "Epoch 87/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0496 - loss: 3.4129 - val_accuracy: 0.0496 - val_loss: 3.4027\n",
      "Epoch 88/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.0499 - loss: 3.4120 - val_accuracy: 0.0654 - val_loss: 3.4023\n",
      "Epoch 89/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.0476 - loss: 3.4129 - val_accuracy: 0.0654 - val_loss: 3.4023\n",
      "Epoch 90/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0502 - loss: 3.4095 - val_accuracy: 0.0654 - val_loss: 3.4022\n",
      "Epoch 91/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0490 - loss: 3.4114 - val_accuracy: 0.0654 - val_loss: 3.4023\n",
      "Epoch 92/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0494 - loss: 3.4117 - val_accuracy: 0.0654 - val_loss: 3.4022\n",
      "Epoch 93/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0471 - loss: 3.4113 - val_accuracy: 0.0496 - val_loss: 3.4022\n",
      "Epoch 94/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0517 - loss: 3.4137 - val_accuracy: 0.0496 - val_loss: 3.4029\n",
      "Epoch 95/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0517 - loss: 3.4108 - val_accuracy: 0.0654 - val_loss: 3.4025\n",
      "Epoch 96/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.0441 - loss: 3.4127 - val_accuracy: 0.0654 - val_loss: 3.4024\n",
      "Epoch 97/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.0425 - loss: 3.4157 - val_accuracy: 0.0654 - val_loss: 3.4023\n",
      "Epoch 98/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.0479 - loss: 3.4142 - val_accuracy: 0.0654 - val_loss: 3.4027\n",
      "Epoch 99/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0475 - loss: 3.4113 - val_accuracy: 0.0654 - val_loss: 3.4025\n",
      "Epoch 100/100\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0475 - loss: 3.4087 - val_accuracy: 0.0496 - val_loss: 3.4026\n"
     ]
    }
   ],
   "source": [
    "rocketsktime_model2 = RocketSktime2(shape = (9996,))\n",
    "rocketsktime_model2.compile(optimizer=Adam(learning_rate=1e-3, beta_1=0.99, beta_2=0.999, epsilon=1e-08), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_sktime2 = rocketsktime_model2.fit(train_rocket_ds, validation_data=val_rocket_ds, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "E8xJHZ4Qsksa",
   "metadata": {
    "id": "E8xJHZ4Qsksa"
   },
   "source": [
    "### **Experiment 3: Add Batch Normalisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jP-Ih-Rdtx6F",
   "metadata": {
    "id": "jP-Ih-Rdtx6F"
   },
   "source": [
    "We summise that the output features of Mini-Rocket may not be normalised, leading to variations in scale across different features. We implement Batch Normalisation to learn the appropriate feature scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "OT7mfhNIsk0H",
   "metadata": {
    "id": "OT7mfhNIsk0H"
   },
   "outputs": [],
   "source": [
    "def RocketSktime3(shape):\n",
    "    block1_input_layer = Input(shape=shape)\n",
    "    layer = BatchNormalization()(block1_input_layer)\n",
    "    layer = Dense(64, activation = \"sigmoid\")(layer)\n",
    "    output_layer = Dense(C, activation=\"softmax\")(layer)\n",
    "    return Model(inputs=block1_input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "WKgepXxug-FL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "WKgepXxug-FL",
    "outputId": "8da473ff-8cde-48b6-d808-9ef6fb251c92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9996</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9996</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">39,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">639,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,015</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_12 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9996\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9996\u001b[0m)                │          \u001b[38;5;34m39,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m639,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)                  │           \u001b[38;5;34m2,015\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">681,807</span> (2.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m681,807\u001b[0m (2.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">661,815</span> (2.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m661,815\u001b[0m (2.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,992</span> (78.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m19,992\u001b[0m (78.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rocketsktime3 = RocketSktime3(shape = (9996,))\n",
    "rocketsktime3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "XrOAuLVeg-HX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XrOAuLVeg-HX",
    "outputId": "cf0edb43-6ac9-4156-b56e-4b1fa702bf12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.3675 - loss: 2.5345 - val_accuracy: 0.2751 - val_loss: 2.6789\n",
      "Epoch 2/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.7613 - loss: 1.4384 - val_accuracy: 0.5072 - val_loss: 1.8656\n",
      "Epoch 3/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8711 - loss: 0.9825 - val_accuracy: 0.6300 - val_loss: 1.3489\n",
      "Epoch 4/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9234 - loss: 0.6931 - val_accuracy: 0.7069 - val_loss: 1.0458\n",
      "Epoch 5/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.9560 - loss: 0.4911 - val_accuracy: 0.7112 - val_loss: 0.8964\n",
      "Epoch 6/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.9729 - loss: 0.3595 - val_accuracy: 0.7191 - val_loss: 0.8168\n",
      "Epoch 7/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9807 - loss: 0.2664 - val_accuracy: 0.7450 - val_loss: 0.7355\n",
      "Epoch 8/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9890 - loss: 0.2002 - val_accuracy: 0.7586 - val_loss: 0.6994\n",
      "Epoch 9/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.9936 - loss: 0.1566 - val_accuracy: 0.7586 - val_loss: 0.6750\n",
      "Epoch 10/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9955 - loss: 0.1212 - val_accuracy: 0.7708 - val_loss: 0.6662\n",
      "Epoch 11/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9955 - loss: 0.0982 - val_accuracy: 0.7694 - val_loss: 0.6783\n",
      "Epoch 12/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9968 - loss: 0.0795 - val_accuracy: 0.7708 - val_loss: 0.6636\n",
      "Epoch 13/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9977 - loss: 0.0658 - val_accuracy: 0.7780 - val_loss: 0.6280\n",
      "Epoch 14/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9988 - loss: 0.0548 - val_accuracy: 0.7737 - val_loss: 0.6316\n",
      "Epoch 15/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9997 - loss: 0.0451 - val_accuracy: 0.7809 - val_loss: 0.6298\n",
      "Epoch 16/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0379 - val_accuracy: 0.7830 - val_loss: 0.6256\n",
      "Epoch 17/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0314 - val_accuracy: 0.7830 - val_loss: 0.6134\n",
      "Epoch 18/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0283 - val_accuracy: 0.7744 - val_loss: 0.6378\n",
      "Epoch 19/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0239 - val_accuracy: 0.7866 - val_loss: 0.6154\n",
      "Epoch 20/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 0.7852 - val_loss: 0.6237\n",
      "Epoch 21/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.7830 - val_loss: 0.6191\n",
      "Epoch 22/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.7881 - val_loss: 0.6151\n",
      "Epoch 23/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 0.7730 - val_loss: 0.6264\n",
      "Epoch 24/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.7759 - val_loss: 0.6276\n",
      "Epoch 25/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.7845 - val_loss: 0.6133\n",
      "Epoch 26/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.7823 - val_loss: 0.6302\n",
      "Epoch 27/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.7816 - val_loss: 0.6403\n",
      "Epoch 28/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.7874 - val_loss: 0.6225\n",
      "Epoch 29/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0086 - val_accuracy: 0.7881 - val_loss: 0.6305\n",
      "Epoch 30/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.7802 - val_loss: 0.6248\n",
      "Epoch 31/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0074 - val_accuracy: 0.7838 - val_loss: 0.6226\n",
      "Epoch 32/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0069 - val_accuracy: 0.7881 - val_loss: 0.6271\n",
      "Epoch 33/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.7859 - val_loss: 0.6279\n",
      "Epoch 34/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.7881 - val_loss: 0.6300\n",
      "Epoch 35/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.7874 - val_loss: 0.6317\n",
      "Epoch 36/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.7845 - val_loss: 0.6384\n",
      "Epoch 37/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.7888 - val_loss: 0.6267\n",
      "Epoch 38/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.7852 - val_loss: 0.6370\n",
      "Epoch 39/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.7881 - val_loss: 0.6369\n",
      "Epoch 40/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.7945 - val_loss: 0.6370\n",
      "Epoch 41/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.7852 - val_loss: 0.6408\n",
      "Epoch 42/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.7895 - val_loss: 0.6384\n",
      "Epoch 43/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.7859 - val_loss: 0.6392\n",
      "Epoch 44/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.7917 - val_loss: 0.6461\n",
      "Epoch 45/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.7895 - val_loss: 0.6475\n",
      "Epoch 46/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7917 - val_loss: 0.6482\n",
      "Epoch 47/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.7874 - val_loss: 0.6497\n",
      "Epoch 48/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7895 - val_loss: 0.6605\n",
      "Epoch 49/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.7924 - val_loss: 0.6422\n",
      "Epoch 50/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.7895 - val_loss: 0.6426\n"
     ]
    }
   ],
   "source": [
    "rocketsktime_model3= RocketSktime3(shape = (9996,))\n",
    "rocketsktime_model3.compile(optimizer=Adam(learning_rate=1e-3, beta_1=0.99, beta_2=0.999, epsilon=1e-08), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_sktime3 = rocketsktime_model3.fit(train_rocket_ds, validation_data=val_rocket_ds, epochs=50, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YLdmZh0dvYQe",
   "metadata": {
    "id": "YLdmZh0dvYQe"
   },
   "source": [
    "This experiment worked! The train fit is perfect, and the validation accuracy is very competitive with the best approaches considered so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VKi_rqmLu0SD",
   "metadata": {
    "id": "VKi_rqmLu0SD"
   },
   "source": [
    "### **Experiment 4: Adding L2 penalisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "toYm13sbu0Za",
   "metadata": {
    "id": "toYm13sbu0Za"
   },
   "outputs": [],
   "source": [
    "def RocketSktime4(shape):\n",
    "    block1_input_layer = Input(shape=shape)\n",
    "    layer = BatchNormalization()(block1_input_layer)\n",
    "    layer = Dense(64, activation = \"sigmoid\", kernel_regularizer = L2(0.0001))(layer)\n",
    "    output_layer = Dense(C, activation=\"softmax\")(layer)\n",
    "    return Model(inputs=block1_input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "HWkwk2QKu7M-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "HWkwk2QKu7M-",
    "outputId": "81d87360-c492-4d87-e7a4-2b954364ba62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_37\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_37\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9996</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_43               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9996</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">39,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_86 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">639,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_87 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,015</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_42 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9996\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_43               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9996\u001b[0m)                │          \u001b[38;5;34m39,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_86 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m639,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_87 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)                  │           \u001b[38;5;34m2,015\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">681,807</span> (2.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m681,807\u001b[0m (2.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">661,815</span> (2.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m661,815\u001b[0m (2.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,992</span> (78.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m19,992\u001b[0m (78.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rocketsktime4 = RocketSktime4(shape = (9996,))\n",
    "rocketsktime4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "adBoTC0Ju7QQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adBoTC0Ju7QQ",
    "outputId": "d3b82808-6f29-4e38-d317-a75ec77cb880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 41ms/step - accuracy: 0.2678 - loss: 2.8853 - val_accuracy: 0.1523 - val_loss: 3.8741\n",
      "Epoch 2/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.5528 - loss: 2.2999 - val_accuracy: 0.3549 - val_loss: 3.0640\n",
      "Epoch 3/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.6430 - loss: 2.0244 - val_accuracy: 0.4188 - val_loss: 2.6608\n",
      "Epoch 4/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7191 - loss: 1.7011 - val_accuracy: 0.5589 - val_loss: 2.0124\n",
      "Epoch 5/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.7570 - loss: 1.4398 - val_accuracy: 0.5582 - val_loss: 1.9254\n",
      "Epoch 6/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.7393 - loss: 1.4153 - val_accuracy: 0.5826 - val_loss: 1.7758\n",
      "Epoch 7/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7529 - loss: 1.3629 - val_accuracy: 0.6070 - val_loss: 1.7871\n",
      "Epoch 8/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.7959 - loss: 1.3015 - val_accuracy: 0.6006 - val_loss: 1.8508\n",
      "Epoch 9/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7783 - loss: 1.3623 - val_accuracy: 0.5812 - val_loss: 1.9172\n",
      "Epoch 10/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step - accuracy: 0.8001 - loss: 1.3367 - val_accuracy: 0.6128 - val_loss: 1.7999\n",
      "Epoch 11/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.8155 - loss: 1.2882 - val_accuracy: 0.6257 - val_loss: 1.8835\n",
      "Epoch 12/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.8117 - loss: 1.2852 - val_accuracy: 0.6078 - val_loss: 1.8919\n",
      "Epoch 13/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8479 - loss: 1.2500 - val_accuracy: 0.6200 - val_loss: 1.8861\n",
      "Epoch 14/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8573 - loss: 1.2057 - val_accuracy: 0.6286 - val_loss: 1.9182\n",
      "Epoch 15/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8504 - loss: 1.1943 - val_accuracy: 0.6264 - val_loss: 1.8292\n",
      "Epoch 16/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.8619 - loss: 1.1530 - val_accuracy: 0.6609 - val_loss: 1.8535\n",
      "Epoch 17/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8716 - loss: 1.0897 - val_accuracy: 0.6228 - val_loss: 1.8466\n",
      "Epoch 18/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.8764 - loss: 1.0746 - val_accuracy: 0.6149 - val_loss: 1.8250\n",
      "Epoch 19/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8608 - loss: 1.0885 - val_accuracy: 0.6444 - val_loss: 1.7450\n",
      "Epoch 20/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.8749 - loss: 1.0707 - val_accuracy: 0.6480 - val_loss: 1.8505\n",
      "Epoch 21/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8510 - loss: 1.1390 - val_accuracy: 0.6430 - val_loss: 1.8284\n",
      "Epoch 22/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.8710 - loss: 1.0998 - val_accuracy: 0.6703 - val_loss: 1.8273\n",
      "Epoch 23/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8802 - loss: 1.0889 - val_accuracy: 0.6645 - val_loss: 1.7271\n",
      "Epoch 24/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8914 - loss: 1.0391 - val_accuracy: 0.6358 - val_loss: 1.8947\n",
      "Epoch 25/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.8818 - loss: 1.0583 - val_accuracy: 0.6329 - val_loss: 1.8431\n",
      "Epoch 26/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8766 - loss: 1.0409 - val_accuracy: 0.6595 - val_loss: 1.7682\n",
      "Epoch 27/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8634 - loss: 1.0758 - val_accuracy: 0.6566 - val_loss: 1.7637\n",
      "Epoch 28/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.8901 - loss: 1.0151 - val_accuracy: 0.6624 - val_loss: 1.8103\n",
      "Epoch 29/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8862 - loss: 1.0212 - val_accuracy: 0.6652 - val_loss: 1.8074\n",
      "Epoch 30/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step - accuracy: 0.8911 - loss: 0.9949 - val_accuracy: 0.6494 - val_loss: 1.8969\n",
      "Epoch 31/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8842 - loss: 0.9832 - val_accuracy: 0.6861 - val_loss: 1.7071\n",
      "Epoch 32/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8918 - loss: 0.9499 - val_accuracy: 0.6667 - val_loss: 1.7745\n",
      "Epoch 33/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.8982 - loss: 0.9471 - val_accuracy: 0.6638 - val_loss: 1.8051\n",
      "Epoch 34/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9086 - loss: 0.9118 - val_accuracy: 0.6782 - val_loss: 1.7056\n",
      "Epoch 35/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9194 - loss: 0.8594 - val_accuracy: 0.6501 - val_loss: 1.7072\n",
      "Epoch 36/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9066 - loss: 0.8875 - val_accuracy: 0.6616 - val_loss: 1.7989\n",
      "Epoch 37/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9123 - loss: 0.8614 - val_accuracy: 0.6853 - val_loss: 1.7058\n",
      "Epoch 38/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9072 - loss: 0.8704 - val_accuracy: 0.7004 - val_loss: 1.7656\n",
      "Epoch 39/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9034 - loss: 0.8797 - val_accuracy: 0.6559 - val_loss: 1.7731\n",
      "Epoch 40/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.9155 - loss: 0.8549 - val_accuracy: 0.6437 - val_loss: 1.9941\n",
      "Epoch 41/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9177 - loss: 0.8556 - val_accuracy: 0.6437 - val_loss: 1.9126\n",
      "Epoch 42/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.9152 - loss: 0.8327 - val_accuracy: 0.6401 - val_loss: 1.8858\n",
      "Epoch 43/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9220 - loss: 0.8061 - val_accuracy: 0.6537 - val_loss: 1.8085\n",
      "Epoch 44/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9194 - loss: 0.7984 - val_accuracy: 0.6466 - val_loss: 1.9653\n",
      "Epoch 45/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9232 - loss: 0.8122 - val_accuracy: 0.6616 - val_loss: 1.7332\n",
      "Epoch 46/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9264 - loss: 0.7752 - val_accuracy: 0.6767 - val_loss: 1.7228\n",
      "Epoch 47/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9301 - loss: 0.7791 - val_accuracy: 0.6818 - val_loss: 1.6094\n",
      "Epoch 48/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9234 - loss: 0.7825 - val_accuracy: 0.6947 - val_loss: 1.6945\n",
      "Epoch 49/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9332 - loss: 0.7609 - val_accuracy: 0.6918 - val_loss: 1.6323\n",
      "Epoch 50/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - accuracy: 0.9472 - loss: 0.7237 - val_accuracy: 0.6667 - val_loss: 1.8781\n"
     ]
    }
   ],
   "source": [
    "rocketsktime_model4 = RocketSktime4(shape = (9996,))\n",
    "rocketsktime_model4.compile(optimizer=Adam(learning_rate=1e-2, beta_1=0.99, beta_2=0.999, epsilon=1e-08), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_sktime4 = rocketsktime_model4.fit(train_rocket_ds, validation_data=val_rocket_ds, epochs=50, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rD7IvO571mBI",
   "metadata": {
    "id": "rD7IvO571mBI"
   },
   "source": [
    "This model was slightly weaker than the unpenalised model. Let's try L1 penalisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X0x9mfa_1ec9",
   "metadata": {
    "id": "X0x9mfa_1ec9"
   },
   "source": [
    "### **Experiment 5: L1 Penalisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "CqKqUz941ei4",
   "metadata": {
    "id": "CqKqUz941ei4"
   },
   "outputs": [],
   "source": [
    "def RocketSktime5(shape):\n",
    "    block1_input_layer = Input(shape=shape)\n",
    "    layer = BatchNormalization()(block1_input_layer)\n",
    "    layer = Dense(64, activation = \"sigmoid\", kernel_regularizer = L1(0.0001))(layer)\n",
    "    output_layer = Dense(C, activation=\"softmax\")(layer)\n",
    "    return Model(inputs=block1_input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "CQWQQiZr1en3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "CQWQQiZr1en3",
    "outputId": "7972c895-b462-4173-be3f-95176a27e045"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_35\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_35\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9996</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_41               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9996</span>)                │          <span style=\"color: #00af00; text-decoration-color: #00af00\">39,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_82 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">639,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_83 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,015</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_40 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9996\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_41               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9996\u001b[0m)                │          \u001b[38;5;34m39,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_82 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │         \u001b[38;5;34m639,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_83 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)                  │           \u001b[38;5;34m2,015\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">681,807</span> (2.60 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m681,807\u001b[0m (2.60 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">661,815</span> (2.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m661,815\u001b[0m (2.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,992</span> (78.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m19,992\u001b[0m (78.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rocketsktime5 = RocketSktime5(shape = (9996,))\n",
    "rocketsktime5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aDB0PZVE1zML",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aDB0PZVE1zML",
    "outputId": "038a0a6c-f01b-4dfb-f2da-bf717b659d2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - accuracy: 0.2573 - loss: 5.0849 - val_accuracy: 0.1516 - val_loss: 6.0094\n",
      "Epoch 2/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5660 - loss: 4.1885 - val_accuracy: 0.3944 - val_loss: 4.0423\n",
      "Epoch 3/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6362 - loss: 3.3333 - val_accuracy: 0.4318 - val_loss: 3.7995\n",
      "Epoch 4/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.6985 - loss: 3.0187 - val_accuracy: 0.6078 - val_loss: 3.2517\n",
      "Epoch 5/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7595 - loss: 2.7937 - val_accuracy: 0.5970 - val_loss: 3.1691\n",
      "Epoch 6/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.7936 - loss: 2.5987 - val_accuracy: 0.6293 - val_loss: 3.0374\n",
      "Epoch 7/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8212 - loss: 2.5298 - val_accuracy: 0.6365 - val_loss: 2.9622\n",
      "Epoch 8/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.8266 - loss: 2.4496 - val_accuracy: 0.6329 - val_loss: 2.8552\n",
      "Epoch 9/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.8328 - loss: 2.3219 - val_accuracy: 0.6724 - val_loss: 2.7658\n",
      "Epoch 10/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8714 - loss: 2.1551 - val_accuracy: 0.6667 - val_loss: 2.6385\n",
      "Epoch 11/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8902 - loss: 1.9890 - val_accuracy: 0.6681 - val_loss: 2.6334\n",
      "Epoch 12/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.8996 - loss: 1.8838 - val_accuracy: 0.6659 - val_loss: 2.5721\n",
      "Epoch 13/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.8993 - loss: 1.7772 - val_accuracy: 0.6961 - val_loss: 2.4029\n",
      "Epoch 14/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8986 - loss: 1.7156 - val_accuracy: 0.6889 - val_loss: 2.3486\n",
      "Epoch 15/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9207 - loss: 1.6317 - val_accuracy: 0.6947 - val_loss: 2.2878\n",
      "Epoch 16/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9150 - loss: 1.5558 - val_accuracy: 0.6681 - val_loss: 2.3405\n",
      "Epoch 17/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9338 - loss: 1.4982 - val_accuracy: 0.6731 - val_loss: 2.3293\n",
      "Epoch 18/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9336 - loss: 1.4393 - val_accuracy: 0.6861 - val_loss: 2.1753\n",
      "Epoch 19/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.9317 - loss: 1.3613 - val_accuracy: 0.6861 - val_loss: 2.1909\n",
      "Epoch 20/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.9428 - loss: 1.2898 - val_accuracy: 0.6659 - val_loss: 2.1163\n",
      "Epoch 21/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9468 - loss: 1.2317 - val_accuracy: 0.6731 - val_loss: 2.1756\n",
      "Epoch 22/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9428 - loss: 1.2083 - val_accuracy: 0.6667 - val_loss: 2.1337\n",
      "Epoch 23/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.9374 - loss: 1.2102 - val_accuracy: 0.6803 - val_loss: 2.1105\n",
      "Epoch 24/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.9578 - loss: 1.1620 - val_accuracy: 0.6868 - val_loss: 2.2271\n",
      "Epoch 25/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9524 - loss: 1.1431 - val_accuracy: 0.6853 - val_loss: 2.1164\n",
      "Epoch 26/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9488 - loss: 1.1254 - val_accuracy: 0.6616 - val_loss: 2.1443\n",
      "Epoch 27/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9531 - loss: 1.1229 - val_accuracy: 0.6789 - val_loss: 2.1382\n",
      "Epoch 28/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9565 - loss: 1.1217 - val_accuracy: 0.7040 - val_loss: 2.1349\n",
      "Epoch 29/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9588 - loss: 1.0790 - val_accuracy: 0.7069 - val_loss: 1.9554\n",
      "Epoch 30/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.9654 - loss: 1.0292 - val_accuracy: 0.6932 - val_loss: 2.0692\n",
      "Epoch 31/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9683 - loss: 0.9880 - val_accuracy: 0.6825 - val_loss: 2.1127\n",
      "Epoch 32/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9671 - loss: 0.9600 - val_accuracy: 0.6983 - val_loss: 2.0395\n",
      "Epoch 33/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9727 - loss: 0.9467 - val_accuracy: 0.6825 - val_loss: 2.0642\n",
      "Epoch 34/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9636 - loss: 0.9482 - val_accuracy: 0.6789 - val_loss: 1.9482\n",
      "Epoch 35/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9656 - loss: 0.9425 - val_accuracy: 0.6861 - val_loss: 1.9162\n",
      "Epoch 36/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9720 - loss: 0.9155 - val_accuracy: 0.7098 - val_loss: 1.8878\n",
      "Epoch 37/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.9712 - loss: 0.8992 - val_accuracy: 0.6789 - val_loss: 1.9883\n",
      "Epoch 38/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9671 - loss: 0.8698 - val_accuracy: 0.6897 - val_loss: 1.9768\n",
      "Epoch 39/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 23ms/step - accuracy: 0.9730 - loss: 0.8528 - val_accuracy: 0.6904 - val_loss: 2.0312\n",
      "Epoch 40/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.9710 - loss: 0.8623 - val_accuracy: 0.6645 - val_loss: 2.1066\n",
      "Epoch 41/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9725 - loss: 0.8863 - val_accuracy: 0.6832 - val_loss: 2.1443\n",
      "Epoch 42/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9697 - loss: 0.9039 - val_accuracy: 0.7004 - val_loss: 1.9400\n",
      "Epoch 43/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.9680 - loss: 0.9167 - val_accuracy: 0.7040 - val_loss: 1.9721\n",
      "Epoch 44/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.9760 - loss: 0.8781 - val_accuracy: 0.6925 - val_loss: 2.0176\n",
      "Epoch 45/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9749 - loss: 0.8539 - val_accuracy: 0.6968 - val_loss: 2.0220\n",
      "Epoch 46/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9782 - loss: 0.8253 - val_accuracy: 0.6739 - val_loss: 2.0249\n",
      "Epoch 47/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9745 - loss: 0.8033 - val_accuracy: 0.6861 - val_loss: 1.9392\n",
      "Epoch 48/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.9857 - loss: 0.7647 - val_accuracy: 0.6796 - val_loss: 1.9250\n",
      "Epoch 49/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.9826 - loss: 0.7274 - val_accuracy: 0.6918 - val_loss: 1.9227\n",
      "Epoch 50/50\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.9777 - loss: 0.7188 - val_accuracy: 0.6904 - val_loss: 1.8773\n"
     ]
    }
   ],
   "source": [
    "rocketsktime_model5 = RocketSktime5(shape = (9996,))\n",
    "rocketsktime_model5.compile(optimizer=Adam(learning_rate=1e-2, beta_1=0.99, beta_2=0.999, epsilon=1e-08), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_sktime5 = rocketsktime_model5.fit(train_rocket_ds, validation_data=val_rocket_ds, epochs=50, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kP79bLPK2mYV",
   "metadata": {
    "id": "kP79bLPK2mYV"
   },
   "source": [
    "Again, the model does not generalise quite so well as the unregularised model. It is sensible to conclude there is useful information across all random components."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
